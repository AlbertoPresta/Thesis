{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import torch \n",
    "import os \n",
    "import cv2 \n",
    "import tensorflow as tf\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential\n",
    "import time\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "# Import Keras and other Deep Learning dependencies\n",
    "from keras.models import Sequential\n",
    "import time\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "import seaborn as sns\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.optimizers import *\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2\n",
    "K.set_image_data_format('channels_last')\n",
    "import cv2\n",
    "import os\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import numpy.random as rng\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIAMESE NETWORK \n",
    "\n",
    "In this notebook I will implement a siames network in tensorflow/keras and try it in omniglot dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('../../omniglot')\n",
    "train_folder = os.path.join(data_path,'images_background')\n",
    "valpath = os.path.join(data_path,'images_evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_class_name = 'character'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(train_folder + '/Sanskrit/character11/0861_06.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each image in the data set has a same of (105, 105, 3)\n",
      "The number of features in any image from the data set are: 33075\n"
     ]
    }
   ],
   "source": [
    "print(\"Each image in the data set has a same of {0}\".format(img.shape))\n",
    "flattened_img = img.flatten()\n",
    "\n",
    "print(\"The number of features in any image from the data set are: {0}\".format(flattened_img.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_class_names(base_class_name):\n",
    "    classes = []\n",
    "    for i in range(1,21):\n",
    "        if i < 10:\n",
    "            classes.append(\"{0}0{1}\".format(base_class_name, i))\n",
    "        else:\n",
    "            classes.append(\"{0}{1}\".format(base_class_name, i))\n",
    "    return classes\n",
    "\n",
    "classes = gen_class_names(base_class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE-HOT ENCODING \n",
    "\n",
    "def generate_one_hot_encoding(classes):\n",
    "    \"\"\"\n",
    "    generate one-hot encoding for each classes\n",
    "    ex character01 = [1,0,0,0,...,0]\n",
    "    \"\"\"\n",
    "    encoder = LabelBinarizer()\n",
    "    transfomed_labels = encoder.fit_transform(classes)\n",
    "    return transfomed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = generate_one_hot_encoding(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(shape, name=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer weights with mean as 0.0 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)\n",
    "\n",
    "\n",
    "\n",
    "def initialize_bias(shape, name=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer bias with mean as 0.5 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIAMESE NETWORK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#one_one_conv = tf.keras.layers.Conv2D(filters=512,kernel_size=1,padding = 'same',activation='relu',input_shape= CONV5_1_SHAPE, name = 'I_level_conv')(feature_conv5)\n",
    "def siamese_model(input_shape):\n",
    "    \n",
    "    input1 = tf.keras.layers.Input(shape = input_shape, name = \"first_image\")\n",
    "    input2 = tf.keras.layers.Input(shape = input_shape, name = \"second_image\")\n",
    "    \n",
    "    #first convolutional block\n",
    "    \n",
    "    conv64 = tf.keras.layers.Conv2D(filters = 64,kernel_size = 10,activation='relu',\n",
    "            kernel_initializer = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 0.01),\n",
    "            input_shape=input_shape,kernel_regularizer=l2(2e-4),\n",
    "            name = \"conv64_10x10\")(input1)\n",
    "    \n",
    "    # maxpooling    \n",
    "    maxpool = tf.keras.layers.MaxPooling2D(name = 'first_maxpooling')(conv64)\n",
    "    \n",
    "    #second convolutional block \n",
    "    \n",
    "    conv128 = tf.keras.layers.Conv2D(filters = 128,kernel_size = 7,activation='relu',\n",
    "            kernel_initializer = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 0.01),\n",
    "            bias_initializer=tf.keras.initializers.RandomNormal(mean = 0.5, stddev = 0.01),\n",
    "            kernel_regularizer=l2(2e-4),\n",
    "            name = \"conv128_7x7\")(maxpool)\n",
    "    \n",
    "    # maxpooling\n",
    "    \n",
    "    maxpool = tf.keras.layers.MaxPooling2D(name = 'second_maxpooling')(conv128)\n",
    "    \n",
    "    #third conovolutional block \n",
    "\n",
    "    conv128_4 = tf.keras.layers.Conv2D(filters = 128, kernel_size = 4, activation='relu',\n",
    "                kernel_initializer=tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 0.01),\n",
    "                bias_initializer=tf.keras.initializers.RandomNormal(mean = 0.5, stddev = 0.01),\n",
    "                kernel_regularizer=l2(2e-4),name = 'conv128_4X4')(maxpool)\n",
    "    \n",
    "    # maxpool \n",
    "    maxpool = tf.keras.layers.MaxPooling2D(name = 'third_maxpooling')(conv128_4)\n",
    "    \n",
    "    conv256 = tf.keras.layers.Conv2D(filters = 256, kernel_size = 4, activation='relu',\n",
    "              kernel_initializer=tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 0.01),\n",
    "              bias_initializer=tf.keras.initializers.RandomNormal(mean = 0.5, stddev = 0.01),kernel_regularizer=l2(2e-4),\n",
    "              name = 'conv256')(maxpool)\n",
    "    \n",
    "    \n",
    "    flatten = tf.keras.layers.Flatten()(conv256)\n",
    "    \n",
    "    dense_layer = tf.keras.layers.Dense(4096,activation = 'sigmoid',kernel_regularizer=l2(1e-3),\n",
    "                kernel_initializer=tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 0.01),\n",
    "                bias_initializer=tf.keras.initializers.RandomNormal(mean = 0.5, stddev = 0.01))(flatten)\n",
    "    \n",
    "    \n",
    "    #################################### secondo nn\n",
    "    \n",
    "        #first convolutional block\n",
    "    \n",
    "    conv64_2 = tf.keras.layers.Conv2D(filters = 64,kernel_size = 10,activation='relu',\n",
    "            kernel_initializer = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 0.01),\n",
    "            input_shape=input_shape,kernel_regularizer=l2(2e-4),\n",
    "            name = \"conv64_10x10_2\")(input2)\n",
    "    \n",
    "    # maxpooling    \n",
    "    maxpool_2 = tf.keras.layers.MaxPooling2D(name = 'first_maxpooling_2')(conv64_2)\n",
    "    \n",
    "    #second convolutional block \n",
    "    \n",
    "    conv128_2 = tf.keras.layers.Conv2D(filters = 128,kernel_size = 7,activation='relu',\n",
    "            kernel_initializer = tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 0.01),\n",
    "            bias_initializer=tf.keras.initializers.RandomNormal(mean = 0.5, stddev = 0.01),\n",
    "            kernel_regularizer=l2(2e-4),\n",
    "            name = \"conv128_7x7_2\")(maxpool_2)\n",
    "    \n",
    "    # maxpooling\n",
    "    \n",
    "    maxpool_2 = tf.keras.layers.MaxPooling2D(name = 'second_maxpooling_2')(conv128_2)\n",
    "    \n",
    "    #third conovolutional block \n",
    "\n",
    "    conv128_4_2 = tf.keras.layers.Conv2D(filters = 128, kernel_size = 4, activation='relu',\n",
    "                kernel_initializer=tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 0.01),\n",
    "                bias_initializer=tf.keras.initializers.RandomNormal(mean = 0.5, stddev = 0.01),\n",
    "                kernel_regularizer=l2(2e-4),name = 'conv128_4X4_2')(maxpool_2)\n",
    "    \n",
    "    # maxpool \n",
    "    maxpool_2 = tf.keras.layers.MaxPooling2D(name = 'third_maxpooling_2')(conv128_4_2)\n",
    "    \n",
    "    conv256_2 = tf.keras.layers.Conv2D(filters = 256, kernel_size = 4, activation='relu',\n",
    "              kernel_initializer=tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 0.01),\n",
    "              bias_initializer=tf.keras.initializers.RandomNormal(mean = 0.5, stddev = 0.01),kernel_regularizer=l2(2e-4),\n",
    "              name = 'conv256_2')(maxpool_2)\n",
    "    \n",
    "    \n",
    "    flatten_2 = tf.keras.layers.Flatten()(conv256_2)\n",
    "    \n",
    "    dense_layer_2 = tf.keras.layers.Dense(4096,activation = 'sigmoid',kernel_regularizer=l2(1e-3),\n",
    "                kernel_initializer=tf.keras.initializers.RandomNormal(mean = 0.0, stddev = 0.01),\n",
    "                bias_initializer=tf.keras.initializers.RandomNormal(mean = 0.5, stddev = 0.01))(flatten_2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    encoder_l = tf.keras.models.Model(inputs = [input1],outputs = [dense_layer])\n",
    "    encoder_r = tf.keras.models.Model(inputs = [input2],outputs = [dense_layer_2])\n",
    "    \n",
    "    \n",
    "    \n",
    "    #### CALCULATE DIFFERENCE \n",
    "    \n",
    "    L1_layer =L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([dense_layer, dense_layer_2])\n",
    "    \n",
    "    prediction = tf.keras.layers.Dense(1,activation='sigmoid',\n",
    "                 bias_initializer=tf.keras.initializers.RandomNormal(mean = 0.5, stddev = 0.01))(L1_distance)\n",
    "    \n",
    "    \n",
    "    siamese_net = tf.keras.models.Model(inputs=[input1,input2],outputs=prediction)\n",
    "    \n",
    "    return siamese_net\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Node' object has no attribute 'output_masks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-40ab1313e32f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msm_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msiamese_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m105\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m105\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-102-16c4601abe90>\u001b[0m in \u001b[0;36msiamese_model\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mL1_layer\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mL1_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mL1_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL1_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdense_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_layer_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     prediction = tf.keras.layers.Dense(1,activation='sigmoid',\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;31m# Handle mask propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mprevious_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collect_previous_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0muser_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_all_none\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_collect_previous_mask\u001b[0;34m(input_tensors)\u001b[0m\n\u001b[1;32m   1439\u001b[0m             \u001b[0minbound_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minbound_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_masks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m             \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Node' object has no attribute 'output_masks'"
     ]
    }
   ],
   "source": [
    "sm_net = siamese_model((105,105,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_siamese_model(input_shape):\n",
    "    \"\"\"\n",
    "        Model architecture based on the one provided in: http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "    \"\"\"\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (10,10), activation='relu',kernel_initializer= 'random_normal', input_shape=input_shape,kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (7,7), activation='relu',kernel_initializer= 'random_normal',kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (4,4), activation='relu',kernel_initializer= 'random_normal',kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(256, (4,4), activation='relu',kernel_initializer= 'random_normal',kernel_regularizer=l2(2e-4)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='sigmoid',kernel_initializer= 'random_normal',kernel_regularizer=l2(1e-3)))\n",
    "    encoded_l = model(left_input)\n",
    "    encoded_r = model(right_input)\n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "    prediction = Dense(1,activation='sigmoid')(L1_distance)\n",
    "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = get_siamese_model((105,105,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           (None, 105, 105, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           (None, 105, 105, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_10 (Sequential)      (None, 4096)         38947648    input_19[0][0]                   \n",
      "                                                                 input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 4096)         0           sequential_10[1][0]              \n",
      "                                                                 sequential_10[2][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            4097        lambda_6[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 38,951,745\n",
      "Trainable params: 38,951,745\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "T.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr = 0.00006)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda10374d56d606404d89697440b2a570f1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
