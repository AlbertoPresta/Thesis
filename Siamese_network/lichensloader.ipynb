{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from class_augmentator.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import random \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import math \n",
    "from PIL import Image \n",
    "\n",
    "import numpy.random as rng\n",
    "import import_ipynb\n",
    "import  class_augmentator \n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lichensloader:\n",
    "    \"\"\"\n",
    "    Class which loads and prepares the lichens dataset. It separates training, validation and evaluation\n",
    "    data. It provides function for getting one-shot task batches \n",
    "    \n",
    "    Attributes:\n",
    "        dataset_path : path to lichen dataset \n",
    "        train_dictionary : dictionary of the files of the train set. This dictionary is used to load \n",
    "        the batch for training and validation \n",
    "        \n",
    "        evaluation_dictionary : dictionary of evaluation set. \n",
    "        image_width\n",
    "        image_height \n",
    "        batch_size\n",
    "        use_augmentation : boolean that alloes us to select if data augmentation is used or not\n",
    "        image augmentator: instanc of class ImageAugmentor that augments images with the affine transformations \n",
    "        referred in the paper     \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, dataset_path, use_augmentation, batch_size):\n",
    "        self.dataset_path = dataset_path \n",
    "        self.train_dictionary = {}\n",
    "        self.evaluation_dictionary = {}\n",
    "        self.image_width = 400\n",
    "        self.image_height = 400\n",
    "        self.channels = 3\n",
    "        self.batch_size = batch_size\n",
    "        self.use_augmentation = use_augmentation \n",
    "        self.train_data = []\n",
    "        self.validation_data = []\n",
    "        self.test_data = []\n",
    "\n",
    "        self.current_train_lichen_index = 0\n",
    "        self.current_validation_lichen_index = 0\n",
    "        self.current_test_lichen_index = 0\n",
    "\n",
    "        self.load_dataset()\n",
    "\n",
    "        if(self.use_augmentation):\n",
    "            self.image_augmentor = self.createAugmentor()\n",
    "        else:\n",
    "            self.use_augmentation = []\n",
    "\n",
    "    \n",
    "    \n",
    "    def load_dataset(self):\n",
    "        \"\"\"\n",
    "        load_dataset into dictionary\n",
    "        \"\"\"\n",
    "        \n",
    "        train_path = os.path.join(self.dataset_path,'train')\n",
    "        test_path = os.path.join(self.dataset_path,'test')\n",
    "        \n",
    "        lichens = os.listdir(train_path)\n",
    "        \n",
    "        for lich in lichens:\n",
    "            if(lich == \".DS_Store\"):\n",
    "                continue\n",
    "            \n",
    "            #Â train part\n",
    "            lich_path = os.path.join(train_path,lich)\n",
    "            spec_lichen_images = os.listdir(lich_path)\n",
    "            res = []\n",
    "            for t in spec_lichen_images:\n",
    "                if(t==\".DS_Store\"):\n",
    "                    continue\n",
    "                else:\n",
    "                    res.append(t)\n",
    "            \n",
    "            self.train_dictionary[lich] = res\n",
    "            \n",
    "            #test part \n",
    "            lich_test_path = os.path.join(test_path,lich)\n",
    "            spec_lichen_images_test = os.listdir(lich_test_path)\n",
    "            res_test = []\n",
    "            for t in spec_lichen_images_test:\n",
    "                if(t == \".DS_Store\"):\n",
    "                    continue\n",
    "                else:\n",
    "                    res_test.append(t)\n",
    "            \n",
    "            self.evaluation_dictionary[lich] = res_test \n",
    "            \n",
    "            \n",
    "    def createAugmentor(self):\n",
    "        \"\"\"\n",
    "        Creates ImageAugmentor object with the parameters for image augmentation \n",
    "        \n",
    "        rotation range was set in -15 to 15 degrees \n",
    "        Shear range was set in between -0.3 and 0.3 radians \n",
    "        Zoom_range = [0.5,2]\n",
    "        shift_range = [5,5]\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        rotation_range = [-15,15]\n",
    "        shear_range = [-0.3 * 180 / math.pi, 0.3 * 180 / math.pi]\n",
    "        zoom_range = [0.5,2]\n",
    "        shift_range = [5,5]\n",
    "        \n",
    "        return class_augmentator.ImageAugmentator(0.5,shear_range,rotation_range,shift_range,zoom_range)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def split_train_datasets(self,tr = 0.8):\n",
    "        \"\"\" Splits the train set in train and validation\n",
    "        Divide the 30 train alphabets in train and validation with\n",
    "        # a 80% - 20% split (24 vs 6 alphabets)\n",
    "        \"\"\"\n",
    "        ts = 1 - tr\n",
    "        available_lichens = list(self.train_dictionary.keys())\n",
    "        number_of_lichens = len(available_lichens)\n",
    "\n",
    "        train_indexes = random.sample(range(0, number_of_lichens - 1), int(tr * number_of_lichens))\n",
    "\n",
    "        # If we sort the indexes in reverse order we can pop them from the list\n",
    "        # and don't care because the indexes do not change\n",
    "        train_indexes.sort(reverse=True)\n",
    "\n",
    "        for index in train_indexes:\n",
    "            self.train_data.append(available_lichens[index])\n",
    "            available_lichens.pop(index)\n",
    "\n",
    "        # The remaining alphabets are saved for validation\n",
    "        self.validation_data = available_lichens\n",
    "        self.test_data = list(self.evaluation_dictionary.keys())\n",
    "            \n",
    "    \n",
    "    def convert_path_list_to_images_and_labels(self, path_list, is_one_shot_task):\n",
    "        \n",
    "        number_of_pairs = int(len(path_list) / 2)\n",
    "        pairs_of_images = [np.zeros((number_of_pairs, self.image_width, self.image_height, 3)) for i in range(2)]\n",
    "        labels = np.zeros((number_of_pairs, 1))\n",
    "\n",
    "        for pair in range(number_of_pairs):\n",
    "            image = Image.open(path_list[pair * 2])\n",
    "            image = np.asarray(image).astype(np.float64)\n",
    "            image = image / image.std() - image.mean()\n",
    "\n",
    "            pairs_of_images[0][pair, :, :, 0] = image\n",
    "            image = Image.open(path_list[pair * 2 + 1])\n",
    "            image = np.asarray(image).astype(np.float64)\n",
    "            image = image / image.std() - image.mean()\n",
    "\n",
    "            pairs_of_images[1][pair, :, :, 0] = image\n",
    "            if not is_one_shot_task:\n",
    "                if (pair + 1) % 2 == 0:\n",
    "                    labels[pair] = 0\n",
    "                else:\n",
    "                    labels[pair] = 1\n",
    "\n",
    "            else:\n",
    "                if pair == 0:\n",
    "                    labels[pair] = 1\n",
    "                else:\n",
    "                    labels[pair] = 0\n",
    "\n",
    "        if not is_one_shot_task:\n",
    "            random_permutation = np.random.permutation(number_of_pairs)\n",
    "            labels = labels[random_permutation]\n",
    "            pairs_of_images[0][:, :, :,\n",
    "                               :] = pairs_of_images[0][random_permutation, :, :, :]\n",
    "            pairs_of_images[1][:, :, :,\n",
    "                               :] = pairs_of_images[1][random_permutation, :, :, :]\n",
    "\n",
    "        return pairs_of_images, labels\n",
    "    \n",
    "    \n",
    "    \n",
    "    def create_pairs_for_batch(self):\n",
    "        \"\"\"\n",
    "        creare 32 coppie di immagini, 16 uguali e 16 diverse   \n",
    "        \"\"\"\n",
    "\n",
    "        available_training_cat = self.train_data\n",
    "        categories = rng.choice(available_training_cat,size=(self.batch_size,),replace=True)\n",
    "        pairs=[np.zeros((self.batch_size, self.image_height, self.image_width,3),np.int32) for i in range(2)]\n",
    "        targets=np.zeros((self.batch_size,))\n",
    "        targets[self.batch_size//2:] = 1\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            category = categories[i]\n",
    "            # load category of lichen\n",
    "            lichen_category = self.train_dictionary[category]\n",
    "\n",
    "            idx_1 = rng.randint(0, len(lichen_category))\n",
    "            #prima immagine\n",
    "            direc = os.path.join(\"patches/train/\" + category,lichen_category[idx_1] )\n",
    "\n",
    "            image_1 = Image.open(direc)\n",
    "            image_1 = np.asarray(image_1).astype(np.float64)\n",
    "            image_1 = image_1 / image_1.std() - image_1.mean()\n",
    "            pairs[0][i,:,:,:] = image_1\n",
    "\n",
    "            if i >= self.batch_size // 2:\n",
    "                idx_2 = (idx_1 + rng.randint(1,len(lichen_category))) % len(lichen_category)\n",
    "                direc = os.path.join(\"patches/train/\" + category,lichen_category[idx_2] )\n",
    "                image_2 = Image.open(direc)\n",
    "                image_2 = np.asarray(image_2).astype(np.float64)\n",
    "                image_2 = image_2 / image_2.std() - image_2.mean()\n",
    "                pairs[1][i,:,:,:] = image_2\n",
    "\n",
    "            else:\n",
    "                temp_cat = copy.deepcopy(available_training_cat)\n",
    "                temp_cat.pop(temp_cat.index(category))\n",
    "                category_2 =  rng.choice(temp_cat,size = 1, replace = False)[0]\n",
    "                lichen_category_2 = self.train_dictionary[category_2]\n",
    "                idx_2 = rng.randint(0, len(lichen_category_2))\n",
    "                direc = os.path.join(\"patches/train/\" + category_2,lichen_category_2[idx_2])\n",
    "                image_2 = Image.open(direc)\n",
    "                image_2 = np.asarray(image_2).astype(np.float64)\n",
    "                image_2 = image_2 / image_2.std() - image_2.mean()\n",
    "                \n",
    "                pairs[1][i,:,:,:] = image_2\n",
    "        return pairs, targets\n",
    "    \n",
    "    def get_one_shot_batch(self, support_set_size,is_validation):\n",
    "        \"\"\"\n",
    "        Single image that will be compared with a support set of images. It returns the pair \n",
    "        if images to be compared by the model and it's label (FIRST PAIR ALWAYS 1) AND REMAINING \n",
    "        ONES ARE 0'S\n",
    "        \"\"\"\n",
    "    \n",
    "        if is_validation:\n",
    "            lichens = self.validation_data \n",
    "            current_lichen_index = self.current_validation_lichen_index\n",
    "            dictionary = self.train_dictionary\n",
    "        else:\n",
    "            lichens = self.test_data \n",
    "            current_lichen_index = self.current_test_lichen_index\n",
    "            dictionary = self.evaluation_dictionary\n",
    "            \n",
    "        # prendo in considerazione uno specifico lichene\n",
    "        current_lichen = lichens[current_lichen_index]\n",
    "        #considero le immagini disponibili per questo specifico lichene\n",
    "        available_lichen_images = list(dictionary[ current_lichen].keys()) \n",
    "        number_of_lichen_images  = len(available_lichen_images)\n",
    "        \n",
    "        batch_images_path = []\n",
    "        \n",
    "        #scelgo un indice casuale e predo un immagine di test\n",
    "        text_character_index = random.sample(range(0,number_of_lichen_images),2) \n",
    "        #immagine di test\n",
    "        test_L = available_lichen_images[text_character_index[0]]\n",
    "        L = available_lichen_images[text_character_index[1]]\n",
    "        \n",
    "        batch_images_path.append(test_L) # appendo immagine da verificare\n",
    "        batch_images_path.append(L) # appendo unica immagine uguale \n",
    "        \n",
    "        #ora devo scegliere causalmente altre (support_set_size -1) immagini per il support set \n",
    "        \n",
    "        categories = rng.choice(lichens.pop(lichens.index(current_lichen)),size = support_set_size -1, replace = False)\n",
    "        \n",
    "        for i in range(categories):\n",
    "            cat = categories[i]\n",
    "            available_lichen_images = list(dictionary[cat].keys())\n",
    "            number_of_lichen_images  = len(available_lichen_images)\n",
    "            text_character_index = random.sample(range(0,number_of_lichen_images),1)\n",
    "            temp_L = available_lichen_images[text_character_index[0]]\n",
    "            batch_images_path.append(test_L)\n",
    "            batch_images_path.append(temp_L)\n",
    "        \n",
    "        images, labels = self._convert_path_list_to_images_and_labels(bacth_images_path, is_one_shot_task=True)\n",
    "        \n",
    "        return images, labels\n",
    "    \n",
    "    \n",
    "    def one_shot_test(self, model, support_set_size, number_of_tasks_per_L,is_validation):\n",
    "        if is_validation:\n",
    "            lichens = self.validation_data\n",
    "            print('\\nMaking One Shot Task on validation alphabets:')\n",
    "        else:\n",
    "            lichens = self.test_data\n",
    "            print('\\nMaking One Shot Task on evaluation alphabets:')\n",
    "        \n",
    "        mean_global_accuracy = 0\n",
    "        \n",
    "        for lich in lichens:\n",
    "            mean_alphabet_accuracy = 0\n",
    "            for _ in range(number_of_tasks_per_L):\n",
    "                images, _ = self.get_one_shot_batch(support_set_size, is_validation=is_validation)\n",
    "                probabilities = model.predict_on_batch(images)\n",
    "\n",
    "                # Added this condition because noticed that sometimes the outputs\n",
    "                # of the classifier was almost the same in all images, meaning that\n",
    "                # the argmax would be always by defenition 0.\n",
    "                if np.argmax(probabilities) == 0 and probabilities.std()>0.01:\n",
    "                    accuracy = 1.0\n",
    "                else:\n",
    "                    accuracy = 0.0\n",
    "\n",
    "                mean_alphabet_accuracy += accuracy\n",
    "                mean_global_accuracy += accuracy\n",
    "\n",
    "            mean_alphabet_accuracy /= number_of_tasks_per_alphabet\n",
    "            if is_validation:\n",
    "                self.current_validation_lichen_inde\\x += 1\n",
    "            else:\n",
    "                self.current_test_lichen_index += 1\n",
    "\n",
    "        mean_global_accuracy /= (len(alphabets) *\n",
    "                                 number_of_tasks_per_alphabet)\n",
    "\n",
    "        print('\\nMean global accuracy: ' + str(mean_global_accuracy))\n",
    "\n",
    "        # reset counter\n",
    "        if is_validation:\n",
    "            self._current_validation_alphabet_index = 0\n",
    "        else:\n",
    "            self._current_evaluation_alphabet_index = 0\n",
    "\n",
    "        return mean_global_accuracy\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda10374d56d606404d89697440b2a570f1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
