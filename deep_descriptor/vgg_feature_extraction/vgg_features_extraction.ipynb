{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import shutil \n",
    "from os import listdir, makedirs, getcwd, remove \n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser \n",
    "import matplotlib.image as mimg\n",
    "\n",
    "import tensorflow as tf \n",
    "from keras import layers \n",
    "from keras import models \n",
    "from keras import optimizers \n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array \n",
    "\n",
    "\n",
    "import import_ipynb\n",
    "import define_svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_image(running_corrects,val_running_corrects, running_loss,val_running_loss, title, direc):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(15,5))\n",
    "    fig.suptitle(title)\n",
    "    ax1.plot(running_corrects)\n",
    "    ax1.plot(val_running_corrects)\n",
    "    ax1.set_title('model accuracy')\n",
    "\n",
    "    ax1.legend(['train', 'test'], loc='upper left')\n",
    "    ax2.plot(running_loss)\n",
    "    ax2.plot(val_running_loss)\n",
    "    ax2.set_title('model loss')\n",
    "\n",
    "    ax2.legend(['train', 'test'], loc='upper left')\n",
    "    \n",
    "    c = ['accuracy','loss']\n",
    "    j = 0\n",
    "    for ax in [ax1,ax2]:\n",
    "        \n",
    "        ax.set(xlabel='epochs', ylabel=c[j])\n",
    "        j = j+1\n",
    "    ax1.grid()\n",
    "    ax2.grid()\n",
    "    plt.savefig(direc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLLECTING DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_pth = '../../../patches/train'\n",
    "species = listdir(species_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe with species and it's path for the image patch!\n",
    "lichens =[]\n",
    "\n",
    "for sp in species:\n",
    "    dr = join(join(species_pth, sp))\n",
    "    al_img = listdir(dr)\n",
    "    \n",
    "    for imgs in al_img:\n",
    "        img_dir =join(dr,imgs)\n",
    "        lichens.append((sp, img_dir))\n",
    "\n",
    "        \n",
    "# create dataframe\n",
    "\n",
    "\n",
    "lichens_dataframe =pd.DataFrame(data = lichens, columns = ['category', 'image'],index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of lichens patch in the dataset: \", len(lichens))\n",
    "fl_count = lichens_dataframe['category'].value_counts()\n",
    "print(\"lichens patch in each category: \")\n",
    "print(fl_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize some lichen's crops from each category\n",
    "\n",
    "# A list for storing names of some random samples from each category\n",
    "random_samples = []\n",
    "\n",
    "# Get samples fom each category \n",
    "for category in fl_count.index:\n",
    "    samples = lichens_dataframe['image'][lichens_dataframe['category'] == category].sample(4).values\n",
    "    for sample in samples:\n",
    "        random_samples.append(sample)\n",
    "print(len(random_samples))\n",
    "        \n",
    "# Plot the samples\n",
    "f, ax = plt.subplots(4,4, figsize=(15,10))\n",
    "for i,sample in enumerate(random_samples[:16]):\n",
    "    ax[i//4, i%4].imshow(mimg.imread(random_samples[i]))\n",
    "    ax[i//4, i%4].axis('off')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir -p data/train\n",
    "%mkdir -p data/valid\n",
    "current_dir_train = join(getcwd(),'data/train')\n",
    "current_dir_val = join(getcwd(),'data/valid')\n",
    "\n",
    "for sp in species:\n",
    "    join(current_dir_train),sp\n",
    "    makedirs(join(current_dir_train,sp))\n",
    "current_dir_val = join(getcwd(),'data/valid')\n",
    "\n",
    "for sp in species:\n",
    "    join(current_dir_val),sp\n",
    "    makedirs(join(current_dir_val,sp))\n",
    "\n",
    "    for sp in species:\n",
    "    join(current_dir_val),sp\n",
    "    makedirs(join(current_dir_val,sp))\n",
    "\n",
    "\n",
    "# move 75% of the images in training direcory and the remaining in the validation directory\n",
    "for category in fl_count.index:\n",
    "    samples =lichens_dataframe['image'][lichens_dataframe['category'] == category].values\n",
    "    tr_num = len(samples)*75//100\n",
    "    perm = np.random.permutation(samples)\n",
    "    for i in range(tr_num):\n",
    "        print(i)\n",
    "        name = perm[i].split('/')[-1]\n",
    "        shutil.copyfile(perm[i],'data/train/'+ str(category) + '/' + name)\n",
    "    print('*****************************************************')\n",
    "    for i in range(tr_num,len(samples)):\n",
    "        print(i)\n",
    "        name = perm[i].split('/')[-1]\n",
    "        shutil.copyfile(perm[i],'data/valid/'+ str(category) + '/' + name)       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING PRE-TRAINED CONVNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights = 'imagenet', include_top = False, input_shape = (100, 100, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE EXTRACTION \n",
    "\n",
    "We can extract features of our images dataset using a pretrained model. This is called Feature Extraction. There are 2 ways to use this method, first one doesn't support data augmentation, but however the second method is usable with data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NO DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function which extracts features, and then train an SVM or another neural network\n",
    "\n",
    "current_dir_train = join(getcwd(),'data/train')\n",
    "current_dir_val = join(getcwd(),'data/valid')\n",
    "def feature_extraction(directory, sample_count):\n",
    "    \n",
    "    # pre_allocated memory\n",
    "    #features = []\n",
    "    #labels_dummy = []\n",
    "    features = np.zeros(shape = (sample_count,3,3,512))\n",
    "    labels_dummy = np.zeros(shape = (sample_count,20))\n",
    "    labels =np.zeros(shape = (sample_count,1))\n",
    "    \n",
    "    generator = ImageDataGenerator(rescale = 1./255).flow_from_directory(directory, target_size = (100, 100), \n",
    "                                                                            batch_size = batch_size, class_mode = 'categorical')\n",
    "    \n",
    "    \n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    \n",
    "    print('enter in loop')\n",
    "    \n",
    "    for input_batch, labels_batch in generator:\n",
    "        \n",
    "        features_batch = conv_base.predict(input_batch)\n",
    "        features[i*batch_size : (i + 1)*batch_size] = features_batch \n",
    "        labels_dummy[i*batch_size : (i + 1)*batch_size] = labels_batch\n",
    "        #features.append(features_batch)\n",
    "        #labels_dummy.append(labels_batch)\n",
    "        \n",
    "        i = i + 1\n",
    "        \n",
    "        if i*batch_size >= sample_count:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    #features = np.array(features)\n",
    "    #labels_dummy = np.array(labels_dummy)\n",
    "    return features, labels_dummy\n",
    "    \n",
    "    \n",
    "    \n",
    "train_features, train_labels_dummy = feature_extraction(current_dir_train, 1200)   \n",
    "    \n",
    "validation_features, validation_labels_dummy = feature_extraction(current_dir_val, 400)   \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels vector \n",
    "def from_dummy_to_labels(dummy_vec):\n",
    "    res = np.zeros(dummy_vec.shape[0])\n",
    "    for i in range(dummy_vec.shape[0]):\n",
    "        tmp = list(dummy_vec[i])\n",
    "        res[i] = tmp.index(1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = from_dummy_to_labels(train_labels_dummy)\n",
    "validation_labels = from_dummy_to_labels(validation_labels_dummy)\n",
    "\n",
    "train_features = np.reshape(train_features, (1200, 3 * 3 * 512))\n",
    "validation_features = np.reshape(validation_features, (400, 3 * 3 * 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN A SVM MODEL  WITH EXTRACTED FEATURES!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc, _ , _ = define_svm.define_and_train_svm(train_features, training_labels, 'linear')\n",
    "svc.score(validation_features,validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import chi2_kernel\n",
    "c = chi2_kernel(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "svc  = OneVsRestClassifier(SVC(kernel = 'precomputed'),n_jobs = -1)\n",
    "svc = svc.fit(c,training_labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc, mean , gram = define_svm.define_and_train_svm(train_features, training_labels, 'precomputed',distance = define_svm.chisquared_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing some test on svm \n",
    "def test_accuracy(test_features,features,gram, test_label,svc):\n",
    "    num_objects = features.shape[0]\n",
    "    res = []\n",
    "    prediction = []\n",
    "    for i,ft in enumerate(test_features):\n",
    "        pred = svc.predict(np.array([np.dot(gram, ft)]))\n",
    "        prediction.append(pred[0])\n",
    "        #print(i,\": \",pred,\" : \",test_label[i])\n",
    "        if(pred==test_label[i]):\n",
    "            res.append(1)\n",
    "        else:\n",
    "            res.append(0)\n",
    "\n",
    "    res = np.array(res).reshape(-1)\n",
    "    return np.sum(res)/res.shape, np.array(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, pred = test_accuracy(validation_features ,train_features,c, validation_labels, svc)\n",
    "\n",
    "print(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saeing he model \n",
    "import pickle\n",
    "filename = 'svm_with_pre_trained_net.sav'\n",
    "pickle.dump(svc, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN A NEW NEURAL NETWORK (NOT DEEP) TO SEE WHAT HAPPENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(2048, activation='relu', input_dim=3 * 3 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(512, activation='relu', input_dim=3 * 3 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128, activation='relu', input_dim=3 * 3 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(20, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_features, train_labels_dummy,\n",
    "                    epochs = 100,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(validation_features, validation_labels_dummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plot_and_save_image(acc,val_acc,loss,val_loss,'accuracy and loss for model','acc_loss_pretrained_cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(val_loss )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN A NEURAL NET WITH DATA AUGMENTATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.Sequential()\n",
    "model2.add(conv_base)\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(512, activation='relu'))\n",
    "model2.add(layers.Dropout(0.5))\n",
    "model2.add(layers.Dense(128, activation='relu'))\n",
    "model2.add(layers.Dropout(0.3))\n",
    "model2.add(layers.Dense(20, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',\n",
    "        target_size=(100, 100),  \n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')  \n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/valid',\n",
    "        target_size=(100, 100),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=2e-5),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model2.fit_generator(\n",
    "          train_generator,\n",
    "          epochs=50,\n",
    "          validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINE-TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',\n",
    "        target_size=(100, 100),  # all images will be resized to 240x240\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')  # more than two classes\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/valid',\n",
    "        target_size=(100, 100),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = models.Sequential()\n",
    "model3.add(layers.Flatten())\n",
    "model3.add(layers.Dense(512, activation='relu'))\n",
    "model3.add(layers.Dropout(0.5))\n",
    "model3.add(layers.Dense(128, activation='relu'))\n",
    "model3.add(layers.Dropout(0.3))\n",
    "model3.add(layers.Dense(20, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss='binary_crossentropy',optimizer=optimizers.Adam(lr=2e-5),metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "istory = model3.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=6,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = istory.history['acc']\n",
    "val_acc = istory.history['val_acc']\n",
    "loss = istory.history['loss']\n",
    "val_loss = istory.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "f, axes = plt.subplots(1,2,figsize=(14,4))\n",
    "\n",
    "axes[0].plot(epochs, acc, 'bo', label='Training acc')\n",
    "axes[0].plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(epochs, loss, 'bo', label='Training loss')\n",
    "axes[1].plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "axes[1].yaxis.set_label_position(\"right\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator.reset()\n",
    "y_pred = model.predict_generator(validation_generator)\n",
    "y_pred = y_pred.argmax(-1)\n",
    "con_mat = tf.math.confusion_matrix(validation_generator.classes, y_pred)\n",
    "con_mat = np.array(con_mat)\n",
    "#plot_confusion_matrix(cm = con_mat, classes = validation_generator.class_indices.keys(), normalize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda10374d56d606404d89697440b2a570f1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
