{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from keras.applications import VGG16\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from os import listdir, makedirs, getcwd, remove \n",
    " import matplotlib.image as mimg\n",
    "import sys\n",
    "sys.path.append('/Users/admin/Desktop/tesi/Thesis/')\n",
    "from handcrafted_descriptors.grid_classification import utils\n",
    "import tensorflow as tf \n",
    "from keras import layers \n",
    "from keras import models \n",
    "from keras import optimizers \n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn.metrics as skmetrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import import_ipynb\n",
    "import define_svm\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_best_rbf(training_feat, tr_lab, tst_features, tst_lab):\n",
    "    param_grid = {'C': [ 100, ], 'gamma': [  0.1]}\n",
    "    clf0 = GridSearchCV(SVC(kernel='rbf'), param_grid)\n",
    "    svc = clf0.fit(training_feat, tr_lab)\n",
    "    print(\"Best estimator found by grid search : \", clf0.best_estimator_)\n",
    "    y_pred = clf0.predict(tst_features)\n",
    "    print('Accuracy score :', skmetrics.accuracy_score(y_pred, tst_lab))\n",
    "    return clf0,skmetrics.accuracy_score(y_pred, tst_lab)\n",
    "\n",
    "def search_for_best_poly(training_feat, tr_lab, tst_features, tst_lab):\n",
    "    param_grid = {'degree':[2,3,4,5,6,7],'C': [1e-3,1e-2, 1e-1, 1e0, 1e1, 1e2,1e3], 'gamma': [  0.00001,0.0001,0.001, 0.01, 0.1,1]}\n",
    "    clf0 = GridSearchCV(SVC(kernel='degree'), param_grid)\n",
    "    svc = clf0.fit(training_feat, tr_lab)\n",
    "    print(\"Best estimator found by grid search : \", clf0.best_estimator_)\n",
    "    y_pred = clf0.predict(tst_features)\n",
    "    print('Accuracy score :', skmetrics.accuracy_score(y_pred, tst_lab))\n",
    "    return clf0, skmetrics.accuracy_score(y_pred, tst_lab)\n",
    "\n",
    "def create_and_save_confusion_matrix(model, tst_features, tst_lab, species,director, name ):\n",
    "    pred = model.predict(tst_features)\n",
    "    df = utils.evaluated_prediction(pred, tst_lab, species)\n",
    "    cm = utils.build_confusion_matrix(df, pred, tst_lab,species)\n",
    "    utils.plot_confusion_matrix(cm,species,name,director,normalize=True,title='Confusion matrix')\n",
    "    return pred\n",
    "\n",
    "def calculate_and_plot_precision_recall(tst_lab, pred, species, directory, string):\n",
    "    precision, recall, fbeta, support = precision_recall_fscore_support(tst_lab, pred)\n",
    "    \n",
    "    df = pd.DataFrame({\"X\":species, \"precision\":precision,\"recall\":recall,'f1score': fbeta})\n",
    "    df.plot(x=\"X\", y=[\"precision\", \"recall\",'f1score'], kind=\"bar\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(directory +'precision_recall_class4class'+string+'.jpg')\n",
    "    return np.mean(precision), np.mean(recall), np.mean(fbeta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(directory, sample_count):\n",
    "    features = np.zeros(shape = (sample_count,3,3,512))\n",
    "    labels_dummy = np.zeros(shape = (sample_count,20))\n",
    "    labels =np.zeros(shape = (sample_count,1))\n",
    "    \n",
    "    generator = ImageDataGenerator(rescale = 1./255).flow_from_directory(directory, target_size = (100, 100), \n",
    "                                                                            batch_size = batch_size, class_mode = 'categorical')\n",
    "    \n",
    "    i = 0   \n",
    "    print('enter in loop')  \n",
    "    for input_batch, labels_batch in generator:\n",
    "        \n",
    "        features_batch = conv_base.predict(input_batch)\n",
    "        features[i*batch_size : (i + 1)*batch_size] = features_batch \n",
    "        labels_dummy[i*batch_size : (i + 1)*batch_size] = labels_batch\n",
    "        i = i + 1      \n",
    "        if i*batch_size >= sample_count:\n",
    "            break\n",
    "    return features, labels_dummy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels vector \n",
    "def from_dummy_to_labels(dummy_vec):\n",
    "    res = np.zeros(dummy_vec.shape[0])\n",
    "    for i in range(dummy_vec.shape[0]):\n",
    "        tmp = list(dummy_vec[i])\n",
    "        res[i] = tmp.index(1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_image(running_corrects,val_running_corrects, running_loss,val_running_loss, title, direc):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(15,5))\n",
    "    fig.suptitle(title)\n",
    "    ax1.plot(running_corrects)\n",
    "    ax1.plot(val_running_corrects)\n",
    "    ax1.set_title('model accuracy')\n",
    "\n",
    "    ax1.legend(['train', 'test'], loc='upper left')\n",
    "    ax2.plot(running_loss)\n",
    "    ax2.plot(val_running_loss)\n",
    "    ax2.set_title('model loss')\n",
    "\n",
    "    ax2.legend(['train', 'test'], loc='upper left')\n",
    "    \n",
    "    c = ['accuracy','loss']\n",
    "    j = 0\n",
    "    for ax in [ax1,ax2]:\n",
    "        \n",
    "        ax.set(xlabel='epochs', ylabel=c[j])\n",
    "        j = j+1\n",
    "    ax1.grid()\n",
    "    ax2.grid()\n",
    "    plt.savefig(direc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ********************** MAIN *************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_pth = '../../../data/train'\n",
    "species = listdir(species_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe with species and it's path for the image patch!\n",
    "lichens =[]\n",
    "for sp in species:\n",
    "    dr = join(join(species_pth, sp))\n",
    "    al_img = listdir(dr)\n",
    "    \n",
    "    for imgs in al_img:\n",
    "        img_dir =join(dr,imgs)\n",
    "        lichens.append((sp, img_dir))\n",
    "\n",
    "        \n",
    "# create dataframe\n",
    "lichens_dataframe =pd.DataFrame(data = lichens, columns = ['category', 'image'],index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of lichens patch in the dataset: \", len(lichens))\n",
    "fl_count = lichens_dataframe['category'].value_counts()\n",
    "print(\"lichens patch in each category: \")\n",
    "print(fl_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize some lichen's crops from each category\n",
    "\n",
    "# A list for storing names of some random samples from each category\n",
    "random_samples = []\n",
    "\n",
    "# Get samples fom each category \n",
    "for category in fl_count.index:\n",
    "    samples = lichens_dataframe['image'][lichens_dataframe['category'] == category].sample(4).values\n",
    "    for sample in samples:\n",
    "        random_samples.append(sample)\n",
    "print(len(random_samples))\n",
    "        \n",
    "# Plot the samples\n",
    "f, ax = plt.subplots(4,4, figsize=(15,10))\n",
    "for i,sample in enumerate(random_samples[:16]):\n",
    "    ax[i//4, i%4].imshow(mimg.imread(random_samples[i]))\n",
    "    ax[i//4, i%4].axis('off')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING PRE-TRAINED CONVNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = VGG16(weights = 'imagenet', include_top = False, input_shape = (100, 100, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE EXTRACTION \n",
    "\n",
    "We can extract features of our images dataset using a pretrained model. This is called Feature Extraction. There are 2 ways to use this method, first one doesn't support data augmentation, but however the second method is usable with data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NO DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function which extracts features, and then train an SVM or another neural network\n",
    "current_dir_train = '../../../data/train'\n",
    "current_dir_val = '../../../data/valid'\n",
    "train_features, train_labels_dummy = feature_extraction(current_dir_train, 1127)   \n",
    "validation_features, validation_labels_dummy = feature_extraction(current_dir_val, 451)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = from_dummy_to_labels(train_labels_dummy)\n",
    "validation_labels = from_dummy_to_labels(validation_labels_dummy)\n",
    "train_features = np.reshape(train_features, (1127, 3 * 3 * 512))\n",
    "validation_features = np.reshape(validation_features, (451, 3 * 3 * 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN A SVM MODEL  WITH EXTRACTED FEATURES!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc, _ , _ = define_svm.define_and_train_svm(train_features, training_labels, 'linear')\n",
    "svc.score(validation_features,validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = ['Arthonia_radiata','Caloplaca_cerina','Candelariella_reflexa','Candelariella_xanthostigma','Chrysothrix_candelaris','Flavoparmelia_caperata','Gyalolechia_flavorubescens','Hyperphyscia_adglutinata'\n",
    "        ,'Lecanora_argentata','Lecanora_chlarotera','Lecidella_elaeochroma','Melanelixia_glabratula'\n",
    "        ,'Phaeophyscia_orbicularis','Physcia_biziana','Physconia_grisea','Ramalina_farinacea','Ramalina_fastigiata','Xanthomendoza_fallax','Xanthomendoza_fulva','flavoparmenia_soredians']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc  = OneVsRestClassifier(SVC(kernel = 'poly',gamma = 'scale', degree = 8),n_jobs = -1)\n",
    "svc = svc.fit(train_features, training_labels)\n",
    "print(svc.score(validation_features,validation_labels))\n",
    "prd = create_and_save_confusion_matrix(svc, validation_features,validation_labels, species,'results/', '_vgg16_poly8' )\n",
    "a,b,c = calculate_and_plot_precision_recall(validation_labels, prd, species, 'results/', 'pra_poly8')\n",
    "print('precision: ',a)\n",
    "print('recall: ',b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda10374d56d606404d89697440b2a570f1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
