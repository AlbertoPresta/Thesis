{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 564,
     "status": "ok",
     "timestamp": 1605624975491,
     "user": {
      "displayName": "Alberto Presta",
      "photoUrl": "",
      "userId": "15881324122263935626"
     },
     "user_tz": -60
    },
    "id": "TN-QvcpYtriT",
    "outputId": "27793184-ab1e-413f-b90e-7b5fb0eeed83"
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#from google.colab import drive\n",
    "\n",
    "#drive.mount('/content/drive')\n",
    "#os.chdir('/content/drive/My Drive/siamese_netowrk_dissimilarity_calculation')\n",
    "\n",
    "\n",
    "#import sys\n",
    "#sys.path.append('/content/drive/My Drive/siamese_netowrk_dissimilarity_calculation')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 556,
     "status": "ok",
     "timestamp": 1605624978028,
     "user": {
      "displayName": "Alberto Presta",
      "photoUrl": "",
      "userId": "15881324122263935626"
     },
     "user_tz": -60
    },
    "id": "ZIBHsKG5YZUd"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import cv2 \n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Input, Lambda, Dense, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 729,
     "status": "ok",
     "timestamp": 1605624980755,
     "user": {
      "displayName": "Alberto Presta",
      "photoUrl": "",
      "userId": "15881324122263935626"
     },
     "user_tz": -60
    },
    "id": "4x0bIUeGZHCu"
   },
   "outputs": [],
   "source": [
    "# create dictionary of lichens \n",
    "\n",
    "lichens = os.listdir('../data/train')\n",
    "lichens_dict = {}\n",
    "for i,l in enumerate(lichens):\n",
    "    lichens_dict[l] = i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfOz_RRaYDWB"
   },
   "source": [
    "PRIMA COSA: gestire i dati e le immagini delle patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread('../data/train/Arthonia_radiata/Arthonia_radiata_texture01_crop_ 1.jpg')\n",
    "im = cv2.resize(im, (100,100), interpolation = cv2.INTER_AREA)\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 589,
     "status": "ok",
     "timestamp": 1605624983188,
     "user": {
      "displayName": "Alberto Presta",
      "photoUrl": "",
      "userId": "15881324122263935626"
     },
     "user_tz": -60
    },
    "id": "_MkF9b6KX5ZX"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "def compute_accuracy(predictions, labels):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return labels[predictions.ravel() < 0.5].mean()\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1605624985898,
     "user": {
      "displayName": "Alberto Presta",
      "photoUrl": "",
      "userId": "15881324122263935626"
     },
     "user_tz": -60
    },
    "id": "Nzs5wS0VZwCn"
   },
   "outputs": [],
   "source": [
    "def create_lichen_dataframe(pth, lichens_dict):\n",
    "    \"\"\"\n",
    "    l'obiettivo di questa funzione Ã¨ quello di creare un dataframe Pandas che abbia le seguenti colonne : FILEPATH, LABEL, LABEL_ID\n",
    "    \"\"\"\n",
    "\n",
    "    lista_licheni = os.listdir(pth)\n",
    "    lista_totale_licheni  = []\n",
    "    for i,lich in enumerate(lista_licheni):\n",
    "        path_singolo_lichene = os.path.join(pth,lich)\n",
    "        immagini_singolo_lichene = os.listdir(path_singolo_lichene)\n",
    "        for j,img in enumerate(immagini_singolo_lichene):\n",
    "            # salvo immagine_pth, label. e label_id\n",
    "            filepath = os.path.join(path_singolo_lichene, img)\n",
    "            label = lich \n",
    "            label_idx = lichens_dict[lich]\n",
    "            lista_totale_licheni.append([filepath, label, label_idx])\n",
    "\n",
    "\n",
    "    res = pd.DataFrame(data = lista_totale_licheni, columns = ['filepath','class','label'], index = None)  \n",
    "    return res\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 880,
     "status": "ok",
     "timestamp": 1605624990775,
     "user": {
      "displayName": "Alberto Presta",
      "photoUrl": "",
      "userId": "15881324122263935626"
     },
     "user_tz": -60
    },
    "id": "O5vX88kNkeH7",
    "outputId": "1c33166d-9516-4f2c-ccd7-a840181d585e"
   },
   "outputs": [],
   "source": [
    "def create_dataset(df, N_PAIRS):\n",
    "\n",
    "    N_EQUAL =  N_PAIRS // 2 \n",
    "\n",
    "    dataset_equal = np.zeros((N_EQUAL, 2 ,100,100,3))\n",
    "    labels_equal = np.zeros((N_EQUAL,1))\n",
    "\n",
    "    dataset_diff = np.zeros((N_EQUAL, 2 ,100,100,3))\n",
    "    labels_diff = np.zeros((N_EQUAL,1))\n",
    "\n",
    "\n",
    "    # creiamo prima le coppie vere \n",
    "\n",
    "    for i in range(20):\n",
    "        print('lichen: ',i)\n",
    "        temp_df = df[df['label'] == i]\n",
    "        number_of_lichen =temp_df.shape[0]\n",
    "        xtracted_couple = []\n",
    "        cont = 0\n",
    "\n",
    "        while cont < N_EQUAL//20:\n",
    "            im1, im2 = np.random.randint(number_of_lichen, size=2)\n",
    "\n",
    "            if (im1,im2) not in xtracted_couple and (im2,im1) not in xtracted_couple:\n",
    "                im1_pth = temp_df.iloc[im1]['filepath']\n",
    "                im2_pth = temp_df.iloc[im2]['filepath']\n",
    "\n",
    "\n",
    "                image1 = cv2.imread(im1_pth)\n",
    "                image1 = cv2.cvtColor(image1, cv2.COLOR_RGB2BGR)\n",
    "                image1 = cv2.resize(image1,(100,100))\n",
    "                #image1 = image1.astype('float32')\n",
    "                #image1 /= 255.0\n",
    "        \n",
    "        \n",
    "                image2 = cv2.imread(im2_pth)\n",
    "                image2 = cv2.cvtColor(image2, cv2.COLOR_RGB2BGR)\n",
    "                image2 = cv2.resize(image2,(100,100))\n",
    "                #image2 = image2.astype('float32')\n",
    "                #image2 /= 255.0\n",
    "\n",
    "                dataset_equal[i*(N_EQUAL//20) + cont,0,:,:,:] = image1 \n",
    "                dataset_equal[i*(N_EQUAL//20) + cont,1,:,:,:] = image2\n",
    "                labels_equal[i*(N_EQUAL//20) + cont] = 1 \n",
    "                cont = cont + 1\n",
    "            else:\n",
    "                continue\n",
    "  \n",
    "    # now we must deal with pairs fromdifferent species \n",
    "\n",
    "    \n",
    "\n",
    "    print('START RECORDING DIFFERENT PAIRS')\n",
    "    N_DIFF = N_PAIRS//2\n",
    "    i = 0\n",
    "    while  i < N_DIFF:\n",
    "        xtracted_couple = []\n",
    "        sp1 = 0\n",
    "        sp2 = 0\n",
    "        while sp1== sp2:\n",
    "            sp1,sp2 = np.random.randint(20, size=2)\n",
    "    \n",
    "        # extract images \n",
    "\n",
    "        temp_df1 = df[df['label'] == sp1]\n",
    "        temp_df2 = df[df['label'] == sp2]\n",
    "\n",
    "        # extract images\n",
    "        iml1 = np.random.randint(temp_df1.shape[0], size=1)[0]\n",
    "        iml2 = np.random.randint(temp_df2.shape[1], size=1)[0]\n",
    "\n",
    "        if (sp1, iml1 , sp2, iml2) not in xtracted_couple and (sp2,iml2,sp1,iml1)not in xtracted_couple:\n",
    "            print(i)\n",
    "\n",
    "            im1_pth = temp_df1.iloc[iml1]['filepath']\n",
    "            im2_pth = temp_df2.iloc[iml2]['filepath']\n",
    "\n",
    "\n",
    "            image1 = cv2.imread(im1_pth)\n",
    "            image1 = cv2.cvtColor(image1, cv2.COLOR_RGB2BGR)\n",
    "            image1 = cv2.resize(image1,(100,100))\n",
    "            #image1 = image1.astype('float32')\n",
    "            #image1 /= 255.0\n",
    "        \n",
    "        \n",
    "            image2 = cv2.imread(im2_pth)\n",
    "            image2 = cv2.cvtColor(image2, cv2.COLOR_RGB2BGR)\n",
    "            image2 = cv2.resize(image2,(100,100))\n",
    "            #image2 = image2.astype('float32')\n",
    "            #image2 /= 255.0\n",
    "\n",
    "            dataset_diff[i,0,:,:,:] = image1 \n",
    "            dataset_diff[i,1,:,:,:] = image2 \n",
    "\n",
    "            labels_diff[i] = 0\n",
    "            i = i +1 \n",
    "        else:\n",
    "            continue\n",
    "  \n",
    "    X = np.concatenate([dataset_equal, dataset_diff], axis=0)/255\n",
    "    Y = np.concatenate([labels_equal, labels_diff], axis=0)\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DSwR29B3sRB8"
   },
   "outputs": [],
   "source": [
    "df = create_lichen_dataframe('../data/train', lichens_dict)\n",
    "X, Y = create_dataset(df, 6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwbUPpQJsWAP"
   },
   "outputs": [],
   "source": [
    "np.save('training_data.npy',X)\n",
    "np.save('training_labe.npy',Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[0,0,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[0,1,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPsf/mVeoYneSQy9uGxTrg9",
   "collapsed_sections": [],
   "name": "prepare_dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
