{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"mettere_a_post.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNISlnH0ehjUjWUb1hhXeEi"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"KU68m81UMJsA"},"source":["import os\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/My Drive/scattering_network')\n","\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/scattering_network ')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kOduoeiD9OCs"},"source":["from sklearn import metrics\n","from sklearn.metrics import precision_recall_fscore_support\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim\n","from torchsummary import summary\n","from torchvision import datasets, transforms\n","from kymatio.torch import Scattering2D\n","import kymatio.datasets as scattering_datasets\n","import argparse\n","from kymatio.numpy import Scattering2D\n","# Set the parameters of the scattering transform.\n","\n","species = ['Arthonia_radiata','Caloplaca_cerina','Candelariella_reflexa','Candelariella_xanthostigma','Chrysothrix_candelaris','Flavoparmelia_caperata','Gyalolechia_flavorubescens','Hyperphyscia_adglutinata'\n","        ,'Lecanora_argentata','Lecanora_chlarotera','Lecidella_elaeochroma','Melanelixia_glabratula'\n","        ,'Phaeophyscia_orbicularis','Physcia_biziana','Physconia_grisea','Ramalina_farinacea','Ramalina_fastigiata','Xanthomendoza_fallax','Xanthomendoza_fulva','flavoparmenia_soredians']\n","\n","\n","\n","def calculate_and_plot_precision_recall(tst_lab, pred, species):\n","    precision, recall, fbeta, support = precision_recall_fscore_support(tst_lab, pred)  \n","    df = pd.DataFrame({\"X\":species, \"precision\":precision,\"recall\":recall,'f1score': fbeta})\n","    df.plot(x=\"X\", y=[\"precision\", \"recall\",'f1score'], kind=\"bar\")\n","    plt.tight_layout()\n","    return np.mean(precision), np.mean(recall), np.mean(fbeta)\n","\n","\n","def plot_confusion_matrix(cm, classes, acc,normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n","    cm = cm.cpu().numpy()\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    titolo = title + '. Mean accuracy: ' + str(acc)\n","    plt.title(titolo)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=90)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        if cm[i, j] > 0.10:\n","            plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","@torch.no_grad()\n","def get_all_preds(model, loader):\n","    all_preds = torch.tensor([])\n","    all_preds = all_preds.to(device)\n","    for batch in loader:\n","        images, labels = batch \n","        images = images.to(device)\n","        labels = labels.to(device)       \n","        output = model(scattering(images))\n","        _, preds = torch.max(output, 1)\n","        all_preds = torch.cat((all_preds,preds),0)\n","    return all_preds \n","\n","\n","def calculate_accuracy(pred, true_lab):\n","    total = pred.shape[0]\n","    cont = 0\n","    for i in range(pred.shape[0]):\n","        if pred[i] == true_lab[i]:\n","            cont = cont + 1\n","        else:\n","            continue \n","    \n","    return cont/total,cont \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6CvzdlikMWsM"},"source":["!pip install kymatio"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IwgUSitu6ZUt"},"source":["\n","J = 3\n","M, N = 100, 100\n","\n","# Generate a sample signal.\n","x = np.random.randn(3,M, N)\n","\n","# Define a Scattering2D object.\n","S = Scattering2D(J=2,L = 4, shape=(100, 100))\n","\n","\n","\n","# Equivalently, use the alias.\n","Sx = S(x)\n","print(Sx.shape)\n","print(Sx.shape[0]*Sx.shape[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f3sAVxvPMJun"},"source":["\n","\n","class Scattering2dCNN(nn.Module):\n","    '''\n","        Simple CNN with 3x3 convs based on VGG\n","    '''\n","    def __init__(self, in_channels,dim_im, classifier_type='cnn'):\n","        super(Scattering2dCNN, self).__init__()\n","        self.in_channels = in_channels\n","        self.dim_im = dim_im\n","        self.classifier_type = classifier_type\n","        self.build()\n","\n","    def build(self):\n","        cfg = [256, 'M', 512,512]\n","        layers = []\n","        self.K = self.in_channels\n","        self.bn = nn.BatchNorm2d(self.K)\n","        if self.classifier_type == 'cnn':\n","            for v in cfg:\n","                if v == 'M':\n","                    layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n","                else:\n","                    conv2d = nn.Conv2d(self.in_channels, v, kernel_size=3, padding=1)\n","                    layers += [ conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n","                    self.in_channels = v\n","\n","            layers += [nn.AdaptiveAvgPool2d(2)]\n","            self.features = nn.Sequential(*layers)\n","            self.classifier =  nn.Linear(512*4, 20)\n","            self.softmax = nn.LogSoftmax(dim=1)\n","\n","        elif self.classifier_type == 'mlp':\n","            self.classifier = nn.Sequential(\n","                        nn.Linear(self.K*8*8, 512), nn.ReLU(),\n","                        nn.Linear(1024, 1024), nn.ReLU(),\n","                        nn.Linear(1024, 20))\n","            self.features = None\n","\n","        elif self.classifier_type == 'linear':\n","            self.classifier = nn.Linear(self.K*25*25,20)\n","            self.features = None\n","\n","\n","    def forward(self, x):\n","        x = self.bn(x.view(-1, self.K, self.dim_im, self.dim_im))\n","        if self.features:\n","            x = self.features(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.classifier(x)\n","        #x = self.softmax(x)\n","        return x\n","\n","\n","\n","\n","def train(model, device, train_loader, optimizer, epoch, scattering):\n","    model.train()\n","    total_loss = []\n","    running_corrects = []\n","    cont = 0\n","    for batch_idx, (data,target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(scattering(data))\n","        loss = F.cross_entropy(output, target)\n","        total_loss.append(loss.item())\n","        loss.backward()\n","        optimizer.step()\n","        _,preds =torch.max(output, 1)\n","        running_corrects.append(torch.sum(preds == target.data).item()/32)\n","\n","\n","        if batch_idx % 50 == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), len(train_loader.dataset),\n","                  100. * batch_idx / len(train_loader), loss.item()))\n","\n","    total_loss = np.array(total_loss)\n","    running_corrects = np.array(running_corrects)\n","    return np.mean(total_loss), np.mean(running_corrects)*100\n","\n","\n","\n","\n","def test(model, device, test_loader, scattering):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(scattering(data))\n","            test_loss += F.cross_entropy(output, target, reduction = 'sum').item()\n","            pred = output.max(1, keepdim = True)[1]\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","    test_loss /= len(test_loader.dataset)\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n","          test_loss, correct, len(test_loader.dataset),\n","          100. * correct / len(test_loader.dataset)))\n","    \n","    return test_loss, correct, 100. * correct / len(test_loader.dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q7PJGcBBMJxJ"},"source":["\n","\n","\n","transform_train = transforms.Compose([transforms.Resize((100,100)),\n","                                      transforms.RandomHorizontalFlip(),\n","                                      transforms.RandomRotation(10),\n","                                      transforms.RandomAffine(0, shear = 10, scale = (0.6,1.1)),\n","                                      transforms.ColorJitter(brightness = 0.2,contrast = 0.2,saturation = 0.2),\n","                                      transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n","\n","\n","transform = transforms.Compose([transforms.Resize((100,100)),transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n","\n","#training_dataset = datasets.CIFAR10(root = '/data',train = True, download = True, transform = transform_train)\n","#validation_dataset = datasets.CIFAR10(root = '/data',train = True, download = True, transform = transform)\n","\n","data_dir = '../dataset/data/train'\n","data_dir_val = '../dataset/data/valid'\n","training_dataset = datasets.ImageFolder(data_dir, transform=transform_train) # TODO: create the Ima\n","validation_dataset = datasets.ImageFolder(data_dir_val, transform = transform)\n","\n","\n","train_loader = torch.utils.data.DataLoader(training_dataset, batch_size =32, shuffle = True)\n","test_loader = torch.utils.data.DataLoader(validation_dataset, batch_size = 32, shuffle = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TOagmiWhMzjY"},"source":["use_cuda = torch.cuda.is_available()\n","\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","scattering = Scattering2D(J=2,L =4, shape=(100, 100))\n","scattering = scattering.cuda()\n","K = 75\n","model = Scattering2dCNN(K,25,'cnn').to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nzbCm-bUl6Xm"},"source":["summary(model, (K, 25, 25))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_sGXqOHqUvll"},"source":["!pip install hiddenlayer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n5bHwxv7MJz1"},"source":["early_stop = False \n","stopping_count = 0\n","lr = 0.01 \n","max_acc = 0\n","tr_loss_tl = []\n","tr_acc_tl = []\n","tst_loss_tl = []\n","tst_acc_tl = []\n","prev_acc = 0\n","for epoch in range(0,100):\n","    #print('------------------------- ',epoch,' ----------------------------')\n","    if epoch%20 ==0:\n","        optimizer = torch.optim.SGD(model.parameters(), lr = lr, momentum =0.9,weight_decay = 0.0005)\n","        \n","        lr *=0.2\n","    \n","    tr_ls,tr_ac = train(model, device, train_loader, optimizer, epoch +1, scattering)\n","    ts_ls , _ , ts_acc = test(model, device, test_loader, scattering)\n","    if prev_acc > ts_acc:\n","        stopping_count = stopping_count + 1 \n","    prev_acc = ts_acc  \n","    if ts_acc > max_acc:\n","        max_acc = ts_acc\n","\n","    tr_loss_tl.append(tr_ls)\n","    tr_acc_tl.append(tr_ac.item())\n","    tst_loss_tl.append(ts_ls)\n","    tst_acc_tl.append(ts_acc)\n","\n","    if stopping_count > 300:\n","        print(\"EARLY STOPPING PERFORMED AT EPOCH \", epoch)\n","        break "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QttROYSe9Cwl"},"source":["with torch.no_grad():\n","    prediction_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=100000)\n","    test_preds = get_all_preds(model, prediction_loader)\n","\n","\n","c = test_preds.cpu().numpy()\n","true_labels = validation_dataset.targets\n","\n","accuracy, corrects = calculate_accuracy(c, true_labels)\n","print(accuracy)\n","print(corrects)\n","print(max_acc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WecDDk6jMJ2I"},"source":["def plot_and_save_image(running_corrects,val_running_corrects, running_loss,val_running_loss, title, direc):\n","    fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(15,5))\n","    fig.suptitle(title)\n","    for i in range(len(running_corrects)):\n","        running_corrects[i]/=100\n","        val_running_corrects[i]/=100\n","    ax1.plot(running_corrects)\n","    ax1.plot(val_running_corrects)\n","    ax1.set_title('model accuracy')\n","\n","    ax1.legend(['train', 'test'], loc='upper left')\n","    ax2.plot(running_loss)\n","    ax2.plot(val_running_loss)\n","    ax2.set_title('model loss')\n","\n","    ax2.legend(['train', 'test'], loc='upper left')\n","    ylab = ['accuracy','loss']\n","    ii = 0\n","    for ax in [ax1,ax2]:\n","        ax.set(xlabel='epochs', ylabel=ylab[ii])\n","        ii = ii + 1\n","    ax1.grid()\n","    ax2.grid()\n","    plt.savefig(direc)  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v5D3ku7AMJ4-"},"source":["plot_and_save_image(tr_acc_tl,tst_acc_tl, tr_loss_tl,tst_loss_tl, 'wave_shortcnn_lichens', 'results/4_4wave_shortcnn_lichens.jpg')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"faI25P8Qc-Yd"},"source":["\n","classes = os.listdir('../dataset/data/train')\n","def im_convert(tensor):\n","  image = tensor.cpu().clone().detach().numpy()\n","  image = image.transpose(1, 2, 0)\n","  image = image * np.array((0.5, 0.5, 0.5)) + np.array((0.5, 0.5, 0.5))\n","  image = image.clip(0, 1)\n","  return image\n","\n","\n","\n","dataiter = iter(train_loader)\n","images, labels = dataiter.next()\n","fig = plt.figure(figsize=(25, 4))\n","\n","for idx in np.arange(10):\n","  ax = fig.add_subplot(2, 5, idx+1, xticks=[], yticks=[])\n","  plt.imshow(im_convert(images[idx]))\n","  ax.set_title(classes[labels[idx].item()])\n","plt.savefig('results/dataset_with_augmentation.jpg')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YIX6NmoHBtEd"},"source":["validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size = 32, shuffle = True)\n","dataiter = iter(validation_loader)\n","images, labels = dataiter.next()\n","images = images.to(device)\n","labels = labels.to(device)\n","output = model(scattering(images))\n","_, preds = torch.max(output, 1)\n","\n","fig = plt.figure(figsize=(50, 10))\n","\n","for idx in np.arange(8):\n","  ax = fig.add_subplot(2, 4, idx+1, xticks=[], yticks=[])\n","  plt.imshow(im_convert(images[idx]))\n","  ax.set_title(\"{} ({})\".format(str(classes[preds[idx].item()]), str(classes[labels[idx].item()])), color=(\"green\" if preds[idx]==labels[idx] else \"red\"))\n","plt.savefig('results/evaluate_cnnshort_6.jpg')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kt5P2CCGcx1L"},"source":["# Create confusion matrix"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"Vp2TCplSwzN4"},"source":["def calculate_and_plot_precision_recall(tst_lab, pred, species):\n","    precision, recall, fbeta, support = precision_recall_fscore_support(tst_lab, pred)  \n","    df = pd.DataFrame({\"X\":species, \"precision\":precision,\"recall\":recall,'f1score': fbeta})\n","    df.plot(x=\"X\", y=[\"precision\", \"recall\",'f1score'], kind=\"bar\")\n","    plt.tight_layout()\n","    return np.mean(precision), np.mean(recall), np.mean(fbeta)\n","\n","\n","def plot_confusion_matrix(cm, classes, acc,normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n","    cm = cm.cpu().numpy()\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    titolo = title + '. Mean accuracy: ' + str(acc)\n","    plt.title(titolo)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=90)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        if cm[i, j] > 0.10:\n","            plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","@torch.no_grad()\n","def get_all_preds(model, loader):\n","    all_preds = torch.tensor([])\n","    all_preds = all_preds.to(device)\n","    for batch in loader:\n","        images, labels = batch \n","        images = images.to(device)\n","        labels = labels.to(device)       \n","        output = model(scattering(images))\n","        _, preds = torch.max(output, 1)\n","        all_preds = torch.cat((all_preds,preds),0)\n","    return all_preds \n","\n","with torch.no_grad():\n","    prediction_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=100000)\n","    test_preds = get_all_preds(model, prediction_loader)\n","\n","def calculate_accuracy(pred, true_lab):\n","    total = pred.shape[0]\n","    cont = 0\n","    for i in range(pred.shape[0]):\n","        if pred[i] == true_lab[i]:\n","            cont = cont + 1\n","        else:\n","            continue \n","    \n","    return cont/total,cont \n","\n","\n","c = test_preds.cpu().numpy()\n","true_labels = validation_dataset.targets\n","\n","accuracy, corrects = calculate_accuracy(c, true_labels)\n","print(accuracy)\n","print(corrects)\n","\n","stacked = torch.stack((torch.Tensor(validation_dataset.targets),test_preds.cpu()),dim=1)\n","cmt = torch.zeros(20,20, dtype=torch.int64)\n","for p in stacked:\n","    tl, pl = p.tolist()\n","    cmt[int(tl), int(pl)] = cmt[int(tl), int(pl)] + 1\n","\n","\n","plt.figure(figsize=(11,10))\n","plot_confusion_matrix(cmt,validation_dataset.classes,accuracy,normalize=True)\n","plt.savefig('conf_matrix_scat_cnn.jpg')\n","\n","import pandas as pd\n","\n","a,b,c = calculate_and_plot_precision_recall(list(validation_dataset.targets), list(test_preds.cpu().numpy()), species)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZXNnF9tYqOCQ"},"source":[""],"execution_count":null,"outputs":[]}]}