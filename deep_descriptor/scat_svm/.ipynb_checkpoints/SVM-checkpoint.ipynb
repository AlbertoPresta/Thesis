{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os \n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics as skmetrics\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import itertools\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "#mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = os.listdir('scattered_image_lichen_4_1_2_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,string,directory,dt,normalize=True):\n",
    "    \"\"\"\n",
    "    Function which plots confusion matrix\n",
    "\n",
    "    Input cm = confusion matrix\n",
    "    Input classes = array with class labels\n",
    "    Input string = string to give name of the saved image\n",
    "    Input directory = string to give directory to save the image\n",
    "    Input normalize (False) = If true function will give accuracy instead of pure number\n",
    "    Input Title (Confusion matrix) = title of the image\n",
    "\n",
    "\n",
    "    Output : None\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    accuracy_score = skmetrics.accuracy_score(y_pred, y_test)\n",
    "    plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "    plt.title(' accuracy: ' + str(accuracy_score) + '   best rbf_kernel model: '+ str(dt))\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if(i==j):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(directory +'confusion_matrix'+string+'.jpg')\n",
    "    \n",
    "    \n",
    "def apply_pca_to_train_and_test_images(train_vct, test_vct, perc = .95):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    train_vct = training vector of shape (N_samples, dimensionality)\n",
    "    test_vct = testing vector of shape (N_samples, dimensionality)\n",
    "    perc = percentage of variance that we want ot preserve \n",
    "    \n",
    "    OUTPUT \n",
    "    train_transform = new training vector \n",
    "    test_transform = new test vector \n",
    "    \"\"\"\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_vct)\n",
    "    train_vct = scaler.transform(train_vct)\n",
    "    test_vct = scaler.transform(test_vct)\n",
    "    pca = PCA(perc)\n",
    "    pca.fit(train_vct)\n",
    "    train_transform = pca.transform(train_vct)\n",
    "    test_transform = pca.transform(test_vct)\n",
    "    \n",
    "    return train_transform, test_transform\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_descriptor_from_matfile(ft_path,label_list = species):\n",
    "    feat = loadmat(ft_path)\n",
    "    feat = feat['scattered_image']\n",
    "    lab = ft_path.split('/')[1]\n",
    "    #print(type(lab))\n",
    "    #print(lab.replace(\"_\", \" \"))\n",
    "    lab = label_list.index(lab)\n",
    "    return feat, lab\n",
    "\n",
    "\n",
    "def extract_features(labels_list, or_pt):\n",
    "    data_all = []\n",
    "    data_mean = []\n",
    "    label = []\n",
    "    for i, tp in enumerate(labels_list):\n",
    "        pth = os.path.join(or_pt, tp)\n",
    "        mat_files = os.listdir(pth)\n",
    "        for j,mt in enumerate(mat_files):\n",
    "            path = os.path.join(pth,mt)\n",
    "            x,y = load_descriptor_from_matfile(path)\n",
    "            xall = x.reshape(-1)\n",
    "            xmean = np.sum(np.sum(x,axis = 2),axis = 1)\n",
    "            xmean = xmean.reshape(-1)\n",
    "            data_all.append(xall)\n",
    "            data_mean.append(xmean)\n",
    "            label.append(y)\n",
    "\n",
    "    data_all = np.array(data_all)\n",
    "    data_mean = np.array(data_mean)\n",
    "    label = np.array(label) \n",
    "    return data_all, data_mean, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ['1','2','3','4','5','6','7','8']\n",
    "\n",
    "\n",
    "for cc in c:\n",
    "    print('--------')\n",
    "    print(cc)\n",
    "    f = 'scattered_image_lichen_4_' + cc + '_2_'\n",
    "    labels_list = os.listdir(f)\n",
    "    title_lich = 'lichen_JLM_4'+ cc + '2_'\n",
    "    data_all, data_mean, label = extract_features(labels_list,f)\n",
    "    # PCA REDUCTION \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_mean, label, test_size=0.70, random_state=10, shuffle=True)\n",
    "    svc  = OneVsRestClassifier(SVC(kernel = 'linear',gamma = 'scale'),n_jobs = -1)\n",
    "    svc = svc.fit(X_train, y_train)\n",
    "    linear_score = svc.score(X_test,y_test)\n",
    "    print(linear_score)\n",
    "    \n",
    "    # First grid search to find best parameters\n",
    "    param_grid = {'C': [ 1e2, 1e3, 5e3, 1e4, 5e4], 'gamma': [ 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 0.0001, 0.0005, 0.001, 0.005]}\n",
    "    clf0 = GridSearchCV(SVC(kernel='rbf'), param_grid)\n",
    "    clf = clf0.fit(X_train, y_train)\n",
    "    print(\"Best estimator found by grid search : \", clf.best_estimator_)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('Accuracy score :', skmetrics.accuracy_score(y_pred, y_test))\n",
    "    \n",
    "    plt.figure(figsize = (15,10)) \n",
    "\n",
    "    plot_confusion_matrix(skmetrics.confusion_matrix(y_pred, y_test),labels_list,title_lich,'results/',clf.best_estimator_)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ['1','2','3','4','5','6','7','8']\n",
    "\n",
    "\n",
    "for cc in c:\n",
    "    print('--------')\n",
    "    print(cc)\n",
    "    f = 'scattered_image_lichen_4_' + cc + '_2_'\n",
    "    labels_list = os.listdir(f)\n",
    "    title_lich = 'lichen_JLM_4'+ cc + '2_'\n",
    "    data_all, data_mean, label = extract_features(labels_list,f)\n",
    "    # PCA REDUCTION \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_mean, label, test_size=0.70, random_state=10, shuffle=True)\n",
    "    svc  = OneVsRestClassifier(SVC(kernel = 'linear',gamma = 'scale'),n_jobs = -1)\n",
    "    svc = svc.fit(X_train, y_train)\n",
    "    linear_score = svc.score(X_test,y_test)\n",
    "    print(linear_score)\n",
    "    \n",
    "    # First grid search to find best parameters\n",
    "    param_grid = {'C': [  1e3, 5e3, 1e4], 'gamma': [ 1e-5, 0.0001, 0.0005, 0.001],'degree':[2,3,4,5,6]}\n",
    "    clf0 = GridSearchCV(SVC(kernel='poly'), param_grid)\n",
    "    clf = clf0.fit(X_train, y_train)\n",
    "    print(\"Best estimator found by grid search : \", clf.best_estimator_)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('Accuracy score :', skmetrics.accuracy_score(y_pred, y_test))\n",
    "    \n",
    "    plt.figure(figsize = (15,10)) \n",
    "\n",
    "    plot_confusion_matrix(skmetrics.confusion_matrix(y_pred, y_test),labels_list,title_lich,'results/',clf.best_estimator_)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kymatio\n",
      "  Using cached kymatio-0.2.0-py3-none-any.whl (92 kB)\n",
      "Requirement already satisfied: numpy in /anaconda3/lib/python3.7/site-packages (from kymatio) (1.19.2)\n",
      "Requirement already satisfied: packaging in /anaconda3/lib/python3.7/site-packages (from kymatio) (20.4)\n",
      "Requirement already satisfied: scipy in /anaconda3/lib/python3.7/site-packages (from kymatio) (1.5.2)\n",
      "Requirement already satisfied: configparser in /anaconda3/lib/python3.7/site-packages (from kymatio) (3.5.3)\n",
      "Collecting appdirs\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /anaconda3/lib/python3.7/site-packages (from packaging->kymatio) (2.4.7)\n",
      "Requirement already satisfied: six in /anaconda3/lib/python3.7/site-packages (from packaging->kymatio) (1.15.0)\n",
      "Installing collected packages: appdirs, kymatio\n",
      "Successfully installed appdirs-1.4.4 kymatio-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install kymatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kymatio.numpy import Scattering2D\n",
    "\n",
    "scattering = Scattering2D(J=2, shape=(100, 100))\n",
    "J = 2\n",
    "M, N = 100, 100\n",
    "\n",
    "# Generate a sample signal.\n",
    "x = np.random.randn(3,M, N)\n",
    "\n",
    "# Define a Scattering2D object.\n",
    "S = Scattering2D(J, (M, N))\n",
    "\n",
    "# Calculate the scattering transform.\n",
    "Sx = S.scattering(x)\n",
    "\n",
    "# Equivalently, use the alias.\n",
    "Sx = S(x)\n",
    "Sxx = Sx.reshape(81*3,25,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(243, 25, 25)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sxx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END-TO-END PROCESS HERE IN PYTHON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pylab as pl\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINE TRAINING PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path=\"../../../patches/train\"\n",
    "class_names=os.listdir(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dir = {}\n",
    "for i,c in enumerate(class_names):\n",
    "    class_dir[c] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths=[]\n",
    "image_classes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_list(path):\n",
    "    return (os.path.join(path,f) for f in os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "for training_name in class_names:\n",
    "    dir_=os.path.join(train_path,training_name)\n",
    "    class_path=img_list(dir_)\n",
    "    image_paths+=class_path\n",
    "    for i in range(len(os.listdir(dir_))):\n",
    "        image_classes.append(class_dir[training_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1573"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPEND ALL IMAGE PATH WITH ITS CORRESPONDING LABEL IN A LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=[]\n",
    "for i in range(len(image_paths)):\n",
    "    D.append((image_paths[i],image_classes[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = D\n",
    "random.shuffle(dataset)\n",
    "\n",
    "\n",
    "image_paths, y_train = zip(*train)\n",
    "image_paths_test, y_test = zip(*test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE EXTRACTION \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def extract_features(dataset, jj = 2,l = 4 , image_shape = (3,100,100),sp =1 ):\n",
    "    s = Scattering2D(J=jj, L = l, shape=(100, 100))\n",
    "    N = len(dataset)\n",
    "    sh1 = 1 + l*jj + (l*l*jj*(jj-1))//2\n",
    "    sh2 = 100//(2**jj)\n",
    "    sh3 = 100//(2**jj)\n",
    "    out = []\n",
    "    lab = []\n",
    "    des_list = []\n",
    "    for i,c in enumerate(dataset):\n",
    "        lab.append(c[1])\n",
    "        img = cv2.imread(c[0])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img,(100,100))\n",
    "        img = cv2.normalize(img, None)\n",
    "        im = np.rollaxis(img, 2, 1)\n",
    "        img = np.rollaxis(im,1,0)  \n",
    "        cc = S.scattering(img)\n",
    "        cc = cc.reshape(cc.shape[0]*cc.shape[1],cc.shape[2],cc.shape[3])\n",
    "        xmean = np.sum(np.sum(cc,axis = 2),axis = 1)\n",
    "        xmean = xmean.reshape(-1)        \n",
    "        out.append(xmean)\n",
    "        des_list.append((c,xmean))\n",
    "    out = np.array(out)\n",
    "    lab = np.array(lab)\n",
    "    return out,lab,des_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,train_label,des_list = extract_features(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors_float=train_data.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing K Means clustering on Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import kmeans,vq\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def BOVW(descriptor, k = 400):\n",
    "    voc,variance=kmeans(descriptors_float,k,1)\n",
    "    im_features=np.zeros((len(image_paths),k),\"float32\")\n",
    "    c =des_list[0][1].shape[0]\n",
    "    im_features=np.zeros((len(image_paths),k),\"float32\")\n",
    "    for i in range(len(image_paths)):\n",
    "        words,distance=vq(des_list[i][1].reshape(1, c),voc)\n",
    "        for w in words:\n",
    "            im_features[i][w]+=1\n",
    "    stdslr=StandardScaler().fit(im_features)\n",
    "    im_features=stdslr.transform(im_features)\n",
    "    return im_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import kmeans,vq\n",
    "\n",
    "k=400\n",
    "voc,variance=kmeans(descriptors_float,k,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des_list[0][1].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_features=np.zeros((len(image_paths),k),\"float32\")\n",
    "for i in range(len(image_paths)):\n",
    "    words,distance=vq(des_list[i][1].reshape(1,243),voc)\n",
    "    for w in words:\n",
    "        im_features[i][w]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "stdslr=StandardScaler().fit(im_features)\n",
    "im_features=stdslr.transform(im_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 400)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(max_iter=80000)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.svm import LinearSVC\n",
    "#clf=LinearSVC(max_iter=80000)\n",
    "#clf.fit(im_features,np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda10374d56d606404d89697440b2a570f1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
