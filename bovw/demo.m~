setdir = '../patches/train';


imds = imageDatastore(setdir, 'IncludeSubFolders',true,'LabelSource','foldernames');
disp('end')





%%

TopFolder = fileparts('/Users/admin/Documents/MATLAB/bovw/scaleprop/GaborArray.m');
addpath(TopFolder);

TopFolder = fileparts('/Users/admin/Documents/MATLAB/bovw/GaborFeatureVector/gaborFilterBank.m');
addpath(TopFolder);
%%

tic
[I,res] =divide_image_in_crops('img_prova.jpg');
toc

%%

figure
montage(imds.Files(1:25:end))




 

tbl = countEachLabel(imds);
%% try by himself to extract scale!
c = imds.Files;
class(c);
for t=c
    cont = cell2mat(t);
    disp(cont)
    I = imread(cont);
    [real_features,featureMetricsscalepropagationsift(I);
end


%% training 
tic 
[trainingSet, validationSet] = splitEachLabel(imds, 0.70, 'randomize');
extractor = @scalepropagationsift;
bag = bagOfFeatures(trainingSet, 'CustomExtractor',extractor,'VocabularySize',300);
%bag = bagOfFeatures(trainingSet, 'VocabularySize',300);
toc 
%% visualize some features

img = readimage(imds, 1);
featureVector = encode(bag, img);

% Plot the histogram of visual word occurrences
figure
bar(featureVector)
title('Visual word occurrences')
xlabel('Visual word index')
ylabel('Frequency of occurrence')
%% Train SVM Classifier

SVM_Kernel = 'rbf'; % Can be either 'polynomial' or 'rbf' for example.
SVM_C = 0.1; % Smaller is less overfitting. Default can be 0.1.
SVM_RBF_Gamma = 0.6; % The RBF SVM Kernel gamma. The higher the more complex model, and more prune to overfitting. Default can be 0.6.
visualize_train_val_data = 0; % Boolean (0 or 1) to visualize training and validation data
visualize_sample_FV = 0;
visualize_test_data = 0;
opts = templateSVM('KernelFunction', 'rbf', 'BoxConstraint', SVM_C, 'kernelScale', SVM_RBF_Gamma);
%opts = templateSVM('KernelFunction', 'chisquaredkernel', 'BoxConstraint', SVM_C);
disp(opts)
disp('start')
classifier = trainImageCategoryClassifier(trainingSet, bag, 'LearnerOptions', opts);
disp('end')

%%

save('models/svm_rbf_classic_sift_300.mat', 'classifier');

%%


%thisObjArray = load('mySampleObjectMatfile.mat');
%% Evaluate the classifier on training then validation data
%confMatrix_train = evaluate(classifier, trainingSet);
confMatrix_val = evaluate(classifier,validationSet);
%tran_val_avg_accuracy = (mean(diag(confMatrix_val)) + mean(diag(confMatrix_train))) / 2; % This information should be used to tweak the system parameters for better accuracy

display(mean(diag(confMatrix_val)));


%%
Labs = validationSet.Labels;
c= unique(imds.Labels)
b=cellstr(c);
figure( 'Position', [10 10 900 600])
title('Confusion matrix: SURF detector, grid 8 , kernel rbf, 200 visua words')
plotConfMat(confMatrix_val,b)
%savefig(H,'result/SURF detector, grid 8 , kernel rbf, 200 visua words.fig')

%%
cl = [];
for i = 1:25
    disp(i)
    f = reshape(res(i,:,:,:),[200 200 3]);
    [labelIdx, scores] = predict(classifier, f);
    cl = [cl ; labelIdx];
end 
%%


targets = validationSet.Labels;
outputs = classifier.Labels(labelIdx);
outputs = categorical(outputs);



figure( 'Position', [10 10 900 600])
title('Confusion matrix: SURF detector, grid 8 , kernel rbf, 200 visua words')
plotconfusion(targets,outputs')



%% create prcision and recall vectors 
precision = zeros(28,1);
recall = zeros(28,1);

c= unique(imds.Labels)

b=cellstr(c);

for i =1:size(confMatrix_val,1)
    precision(i)=confMatrix_val(i,i)/sum(confMatrix_val(i,:));
end
for i =1:size(confMatrix_val,1)
    recall(i)=confMatrix_val(i,i)/sum(confMatrix_val(:,i));
end



name = b;
T = table(name,precision,recall)
writetable(T,'Results/pre_rec_DENSESIFTRGBrfb8300')






