{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from distance.ipynb\n",
      "importing Jupyter notebook from Protonet.ipynb\n",
      "importing Jupyter notebook from data.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "import os\n",
    "import cv2\n",
    "import multiprocessing as mp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import import_ipynb\n",
    "import distance\n",
    "import Protonet\n",
    "import data\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_x, train_y, n_way, n_support, n_query, max_epoch,epoch_size,PATH = \"model/protonet.pt\"):\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer,1,gamma = 0.5, last_epoch = -1)\n",
    "    epoch = 0\n",
    "    while(epoch < max_epoch):\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        \n",
    "        for episode in tqdm(range(epoch_size)):\n",
    "            sample = data.extract_sample(n_way, n_support, n_query, train_x, train_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss, output = model.set_forward_loss(sample)\n",
    "            running_loss += output['loss']\n",
    "            running_acc += output['acc']\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        epoch_loss = running_loss / epoch_size\n",
    "        epoch_acc = running_acc / epoch_size\n",
    "        print('Epoch {:d} -- Loss: {:.4f} Acc: {:.4f}'.format(epoch+1,epoch_loss, epoch_acc))\n",
    "        epoch += 1\n",
    "        scheduler.step()\n",
    "    #save the model \n",
    "    \n",
    "    torch.save(model, PATH)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 8s, sys: 8.94 s, total: 1min 17s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "trainx, trainy = data.read_images('omniglot/images_background')\n",
    "testx, testy = data.read_images('omniglot/images_evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 -- Loss: 0.1509 Acc: 0.9540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 -- Loss: 0.0528 Acc: 0.9828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 -- Loss: 0.0430 Acc: 0.9858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 -- Loss: 0.0333 Acc: 0.9882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 -- Loss: 0.0324 Acc: 0.9884\n",
      "CPU times: user 1h 10min 52s, sys: 7min 46s, total: 1h 18min 38s\n",
      "Wall time: 1h 11min 48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Protonet.load_protonet_conv(x_dim=(3,28,28),hid_dim=64,z_dim=64)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "n_way = 60\n",
    "n_support = 5\n",
    "n_query = 5\n",
    "\n",
    "train_x = trainx\n",
    "train_y = trainy\n",
    "\n",
    "max_epoch = 5\n",
    "epoch_size = 500\n",
    "\n",
    "train(model, optimizer, train_x, train_y, n_way, n_support, n_query, max_epoch, epoch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_x, test_y, n_way, n_support, n_query, test_episode):\n",
    "    \"\"\"\n",
    "    Tests the protonet\n",
    "    Args:\n",
    "        model: trained model\n",
    "        test_x (np.array): images of testing set\n",
    "        test_y (np.array): labels of testing set\n",
    "        n_way (int): number of classes in a classification task\n",
    "        n_support (int): number of labeled examples per class in the support set\n",
    "        n_query (int): number of labeled examples per class in the query set\n",
    "        test_episode (int): number of episodes to test on\n",
    "      \"\"\"\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for episode in tqdm(range(test_episode)):\n",
    "        sample = data.extract_sample(n_way, n_support, n_query, test_x, test_y)\n",
    "        loss, output = model.set_forward_loss(sample)\n",
    "        running_loss += output['loss']\n",
    "        running_acc += output['acc']\n",
    "    avg_loss = running_loss / test_episode\n",
    "    avg_acc = running_acc / test_episode\n",
    "    print('Test results -- Loss: {:.4f} Acc: {:.4f}'.format(avg_loss, avg_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results -- Loss: 0.0147 Acc: 0.9968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "n_way = 5\n",
    "n_support = 5\n",
    "n_query = 5\n",
    "\n",
    "test_x = testx\n",
    "test_y = testy\n",
    "\n",
    "test_episode = 1000\n",
    "\n",
    "test(model, test_x, test_y, n_way, n_support, n_query, test_episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda10374d56d606404d89697440b2a570f1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
