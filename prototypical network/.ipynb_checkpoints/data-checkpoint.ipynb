{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from distance.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "import os\n",
    "import cv2\n",
    "import multiprocessing as mp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import import_ipynb\n",
    "import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_alphabets(alphabet_directory_path, alphabet_directory_name):\n",
    "    \"\"\"\n",
    "    Reads all the characters from a given alphabet_directory\n",
    "    \"\"\"\n",
    "    datax = []\n",
    "    datay = []\n",
    "    characters = os.listdir(alphabet_directory_path)\n",
    "    for character in characters:\n",
    "        images = os.listdir(alphabet_directory_path + character + '/')\n",
    "        for img in images:\n",
    "            image = cv2.resize(\n",
    "                cv2.imread(alphabet_directory_path + character + '/' + img),\n",
    "                (28,28)\n",
    "                )\n",
    "            #rotations of image\n",
    "            rotated_90 = ndimage.rotate(image, 90)\n",
    "            rotated_180 = ndimage.rotate(image, 180)\n",
    "            rotated_270 = ndimage.rotate(image, 270)\n",
    "            datax.extend((image, rotated_90, rotated_180, rotated_270))\n",
    "            datay.extend((\n",
    "                alphabet_directory_name + '_' + character + '_0',\n",
    "                alphabet_directory_name + '_' + character + '_90',\n",
    "                alphabet_directory_name + '_' + character + '_180',\n",
    "                alphabet_directory_name + '_' + character + '_270'\n",
    "            ))\n",
    "    return np.array(datax), np.array(datay)\n",
    "\n",
    "def read_images(base_directory):\n",
    "    \"\"\"\n",
    "    Reads all the alphabets from the base_directory\n",
    "    Uses multithreading to decrease the reading time drastically\n",
    "    \"\"\"\n",
    "    datax = None\n",
    "    datay = None\n",
    "    results = []\n",
    "    for directory in os.listdir(base_directory):\n",
    "        results.append(read_alphabets(base_directory + '/' + directory + '/',directory))\n",
    "    for result in results:\n",
    "        if datax is None:\n",
    "            datax = result[0]\n",
    "            datay = result[1]\n",
    "        else:\n",
    "            datax = np.vstack([datax, result[0]])\n",
    "            datay = np.concatenate([datay, result[1]])\n",
    "    return datax, datay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sample(n_way, n_support, n_query, datax, datay):\n",
    "    sample = []\n",
    "    unique_y = np.unique(datay)\n",
    "    K = np.random.choice(unique_y, n_way, replace = False)\n",
    "    for cls in K:\n",
    "        datax_cls = datax[datay==cls]\n",
    "        perm = np.random.permutation(datax_cls)\n",
    "        sample_cls = perm[:(n_support + n_query)]\n",
    "        sample.append(sample_cls)\n",
    "    # sample in the end will be a matrix of dimension  k X n_support + n_query\n",
    "    \n",
    "    sample = np.array(sample) #become a np array of array (matrix)\n",
    "    sample = torch.from_numpy(sample).float() # become a tensor\n",
    "    sample = sample.permute(0,1,4,2,3) \n",
    "    df = {'images': sample, 'n_way': n_way,'n_support': n_support,'n_query': n_query}\n",
    "    return df\n",
    "\n",
    "\n",
    "def display_sample(sample):\n",
    "    \"\"\"\n",
    "    Displays sample in a grid\n",
    "    Args:\n",
    "    sample (torch.Tensor): sample of images to display\n",
    "    \"\"\"\n",
    "    #need 4D tensor to create grid, currently 5D\n",
    "    sample_4D = sample.view(sample.shape[0]*sample.shape[1],*sample.shape[2:])\n",
    "    #make a grid\n",
    "    out = torchvision.utils.make_grid(sample_4D, nrow=sample.shape[1])\n",
    "    plt.figure(figsize = (16,7))\n",
    "    plt.imshow(out.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda10374d56d606404d89697440b2a570f1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
