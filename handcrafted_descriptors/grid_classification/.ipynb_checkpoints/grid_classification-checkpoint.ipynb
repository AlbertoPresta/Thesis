{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "import sys\n",
    "sys.path.append('/Users/admin/Desktop/tesi/Thesis/')\n",
    "import numpy as np # fundamental package for scientific computing\n",
    "import matplotlib.pyplot as plt # package for plot function\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from handcrafted_descriptors.grid_classification import kernels as krn\n",
    "from handcrafted_descriptors.grid_classification import accuracy_and_test as aat\n",
    "from handcrafted_descriptors.grid_classification import utils\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn.metrics as skmetrics\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = ['Arthonia_radiata','Caloplaca_cerina','Candelariella_reflexa','Candelariella_xanthostigma','Chrysothrix_candelaris','Flavoparmelia_caperata','Gyalolechia_flavorubescens','Hyperphyscia_adglutinata'\n",
    "        ,'Lecanora_argentata','Lecanora_chlarotera','Lecidella_elaeochroma','Melanelixia_glabratula'\n",
    "        ,'Phaeophyscia_orbicularis','Physcia_biziana','Physconia_grisea','Ramalina_farinacea','Ramalina_fastigiata','Xanthomendoza_fallax','Xanthomendoza_fulva','flavoparmenia_soredians']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS \n",
    "\n",
    "Functions to extract descriptors from matfile, build svm model and calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_and_calculate_accuracy(train_features,train_lab,test_features,test_lab): \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_features)\n",
    "\n",
    "    #X_train = scaler.transform(train_features)\n",
    "    X_train = train_features\n",
    "    #X_test = scaler.transform(test_features)\n",
    "    X_test = test_features\n",
    "    \n",
    "    clc = []\n",
    "    acc = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    for i in range(1,51):\n",
    "        classifier = KNeighborsClassifier(n_neighbors=i) \n",
    "        classifier.fit(X_train, train_lab)\n",
    "        clc.append(classifier)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        acc_temp = 0\n",
    "        total = y_pred.shape[0]\n",
    "        for j in range(y_pred.shape[0]):\n",
    "            if y_pred[j]==test_lab[j]:\n",
    "                acc_temp = acc_temp + 1\n",
    "        precision, recall, fbeta, support = precision_recall_fscore_support(tst_lab, y_pred)\n",
    "        prec.append(np.mean(precision))\n",
    "        rec.append(np.mean(recall))\n",
    "        acc.append(acc_temp/total)\n",
    "    return acc, prec, rec,clc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_descriptor_from_matfile(ft_path,lab_path):\n",
    "    feat = loadmat(ft_path)\n",
    "    feat = feat['features']\n",
    "    lab = loadmat(lab_path)\n",
    "    lab = lab['labels']\n",
    "    return feat, lab\n",
    "\n",
    "\n",
    "def define_and_train_svm(tr_feature, tr_lab, kernel_type, distance = None):\n",
    "    if distance == None:\n",
    "        print('here')\n",
    "        svc  = OneVsRestClassifier(SVC(kernel = kernel_type,gamma = 'scale'),n_jobs = -1)\n",
    "        svc = svc.fit(tr_feature, tr_lab)\n",
    "        return svc, 0, np.zeros(tr_feature.shape[0])\n",
    "    else:\n",
    "        gram= krn.compute_gram_matrix(tr_feature,distance)\n",
    "        mean = np.mean(gram[np.triu_indices(np.shape(tr_feature)[0])])\n",
    "        gram = np.exp(-(gram/mean)) # generalized Gaussian kernel\n",
    "        svc  = OneVsRestClassifier(SVC(kernel = 'precomputed'),n_jobs = -1)\n",
    "        svc = svc.fit(gram,np.array(tr_lab))\n",
    "        return svc, mean,gram\n",
    "\n",
    "\n",
    "\n",
    "def equal(a,b):\n",
    "    for i in range(a.shape[0]):\n",
    "        if a[i]!=b[i]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_accuracy(test_features,features,kernel,mean, test_label,svc):\n",
    "    num_objects = features.shape[0]\n",
    "    res = []\n",
    "    prediction = []\n",
    "    for i,ft in enumerate(test_features):\n",
    "        if(i%200 ==0):\n",
    "            print(i)\n",
    "\n",
    "        pred = svc.predict(np.array([kernel(ft, features[num, :], mean) for num in range(num_objects)]).reshape(1, -1))\n",
    "        prediction.append(pred[0])\n",
    "        #print(i,\": \",pred,\" : \",test_label[i])\n",
    "        if(pred==test_label[i]):\n",
    "            res.append(1)\n",
    "        else:\n",
    "            res.append(0)\n",
    "\n",
    "    res = np.array(res).reshape(-1)\n",
    "    return np.sum(res)/res.shape, np.array(prediction)\n",
    "\n",
    "\n",
    "def calculate_and_plot_precision_recall(tst_lab, pred, species, directory, string):\n",
    "    precision, recall, fbeta, support = precision_recall_fscore_support(tst_lab, pred)\n",
    "    \n",
    "    df = pd.DataFrame({\"X\":species, \"precision\":precision,\"recall\":recall,'f1score': fbeta})\n",
    "    df.plot(x=\"X\", y=[\"precision\", \"recall\",'f1score'], kind=\"bar\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(directory +'precision_recall_class4class'+string+'.jpg')\n",
    "    return np.mean(precision), np.mean(recall), np.mean(fbeta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_best_rbf(training_feat, tr_lab, tst_features, tst_lab):\n",
    "    param_grid = {'C': [ 1e0, 1e1, 1e2,1e3], 'gamma': [   0.01, 0.1,1]}\n",
    "    clf0 = GridSearchCV(SVC(kernel='rbf'), param_grid)\n",
    "    svc = clf0.fit(training_feat, tr_lab)\n",
    "    print(\"Best estimator found by grid search : \", clf0.best_estimator_)\n",
    "    y_pred = clf0.predict(tst_features)\n",
    "    print('Accuracy score :', skmetrics.accuracy_score(y_pred, tst_lab))\n",
    "    return clf0,skmetrics.accuracy_score(y_pred, tst_lab)\n",
    "\n",
    "def search_for_best_poly(training_feat, tr_lab, tst_features, tst_lab):\n",
    "    param_grid = {'degree':[2,3,4,5,6,7],'C': [1e-3,1e-2, 1e-1, 1e0, 1e1, 1e2,1e3], 'gamma': [  0.00001,0.0001,0.001, 0.01, 0.1,1]}\n",
    "    clf0 = GridSearchCV(SVC(kernel='degree'), param_grid)\n",
    "    svc = clf0.fit(training_feat, tr_lab)\n",
    "    print(\"Best estimator found by grid search : \", clf0.best_estimator_)\n",
    "    y_pred = clf0.predict(tst_features)\n",
    "    print('Accuracy score :', skmetrics.accuracy_score(y_pred, tst_lab))\n",
    "    return clf0, skmetrics.accuracy_score(y_pred, tst_lab)\n",
    "\n",
    "def create_and_save_confusion_matrix(model, tst_features, tst_lab, species, vw,director, name ):\n",
    "    pred = model.predict(tst_features)\n",
    "    df = utils.evaluated_prediction(pred, tst_lab, species)\n",
    "    cm = utils.build_confusion_matrix(df, pred, tst_lab,species)\n",
    "    fig=plt.figure(figsize=(30, 15))\n",
    "    utils.plot_confusion_matrix(cm,species,name,director,normalize=True,title='Confusion matrix')\n",
    "    plt.close()\n",
    "    return pred\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_and_save_knn(acc,prec,rec,direct):\n",
    "    x1 = np.arange(1,51)\n",
    "    plt.plot(x1, acc, label = \"accuracy\",color = 'r')\n",
    "    plt.plot(x1,prec, label = 'precision')\n",
    "    plt.plot(x1, rec, label = 'recall',color = 'g')\n",
    "    plt.xlabel('number of neighbors')\n",
    "    plt.ylabel('percentage (%)')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(direct)\n",
    "    plt.close()\n",
    "\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1score = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "200\n",
      "------------------------------\n",
      "Best estimator found by grid search :  SVC(C=100.0, gamma=1)\n",
      "Accuracy score : 0.8675\n",
      "-----------------------------\n",
      "250\n",
      "------------------------------\n",
      "Best estimator found by grid search :  SVC(C=100.0, gamma=1)\n",
      "Accuracy score : 0.8725\n",
      "-----------------------------\n",
      "300\n",
      "------------------------------\n",
      "Best estimator found by grid search :  SVC(C=100.0, gamma=1)\n",
      "Accuracy score : 0.8725\n",
      "-----------------------------\n",
      "350\n",
      "------------------------------\n",
      "Best estimator found by grid search :  SVC(C=100.0, gamma=1)\n",
      "Accuracy score : 0.8825\n",
      "-----------------------------\n",
      "400\n",
      "------------------------------\n",
      "Best estimator found by grid search :  SVC(C=100.0, gamma=1)\n",
      "Accuracy score : 0.8825\n",
      "-----------------------------\n",
      "450\n",
      "------------------------------\n",
      "Best estimator found by grid search :  SVC(C=10.0, gamma=1)\n",
      "Accuracy score : 0.87\n",
      "-----------------------------\n",
      "500\n",
      "------------------------------\n",
      "Best estimator found by grid search :  SVC(C=100.0, gamma=1)\n",
      "Accuracy score : 0.8825\n",
      "-----------------------------\n",
      "550\n",
      "------------------------------\n",
      "Best estimator found by grid search :  SVC(C=10.0, gamma=1)\n",
      "Accuracy score : 0.8875\n",
      "-----------------------------\n",
      "600\n",
      "------------------------------\n",
      "Best estimator found by grid search :  SVC(C=10.0, gamma=1)\n",
      "Accuracy score : 0.895\n",
      "-----------------------------\n",
      "650\n",
      "------------------------------\n",
      "Best estimator found by grid search :  SVC(C=100.0, gamma=0.1)\n",
      "Accuracy score : 0.87\n",
      "-----------------------------\n",
      "700\n",
      "------------------------------\n",
      "Best estimator found by grid search :  SVC(C=10.0, gamma=1)\n",
      "Accuracy score : 0.895\n",
      "-----------------------------\n",
      "750\n",
      "------------------------------\n",
      "Best estimator found by grid search :  SVC(C=100.0, gamma=0.1)\n",
      "Accuracy score : 0.88\n",
      "-----------------------------\n",
      "800\n",
      "------------------------------\n",
      "Best estimator found by grid search :  SVC(C=10.0, gamma=1)\n",
      "Accuracy score : 0.8975\n",
      "-----------------------------\n",
      "850\n",
      "------------------------------\n",
      "Best estimator found by grid search :  SVC(C=1000.0, gamma=0.01)\n",
      "Accuracy score : 0.8925\n",
      "-----------------------------\n",
      "900\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "visual = [200, 250 ,300, 350 ,  400, 450, 500, 550, 600,650, 700,750,800,850,900]\n",
    "\n",
    "\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1score = []\n",
    "\n",
    "\n",
    "for i,vv in enumerate(visual):\n",
    "    print('-----------------------------')\n",
    "    print(vv)\n",
    "    print('------------------------------')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    trf = '../../../features_for_python_4_opponent_phow/phowf_4_' + str(vv) +'_rbf/training_features.mat'\n",
    "    trlab = '../../../features_for_python_4_opponent_phow/phowf_4_' + str(vv) +'_rbf/training_lab_features.mat'\n",
    "\n",
    "    tstf = '../../../features_for_python_4_opponent_phow/phowf_4_' + str(vv) +'_rbf/testing_features.mat'\n",
    "    tstlab = '../../../features_for_python_4_opponent_phow/phowf_4_' + str(vv) +'_rbf/testing_lab_features.mat'\n",
    "\n",
    "\n",
    "\n",
    "    training_feat,tr_lab = load_descriptor_from_matfile(trf, trlab)\n",
    "    tst_features, tst_lab = load_descriptor_from_matfile(tstf,tstlab)\n",
    "\n",
    "    tr_lab = tr_lab -1\n",
    "    tst_lab = tst_lab -1\n",
    "    \n",
    "    svm, score = search_for_best_rbf(training_feat, tr_lab, tst_features, tst_lab)\n",
    "    name = \"phow_4_\"+str(vv)+'opponent_'\n",
    "    direc = \"results/phow_4_opponent/confusion_matrix/\"\n",
    "    pred = create_and_save_confusion_matrix(svm, tst_features, tst_lab, species, vv,direc,name)\n",
    "    \n",
    "    a,b,c = calculate_and_plot_precision_recall(tst_lab, pred, species, 'results/phow_8_opponent/precision_recall/', 'phow_6_' + str(vv) +'_')\n",
    "\n",
    "\n",
    "    #knnacc, knnprec, knnrec ,_ = train_model_and_calculate_accuracy(training_feat,tr_lab,tst_features,tst_lab)\n",
    "    \n",
    "    #classifier = KNeighborsClassifier(n_neighbors=1) \n",
    "    #classifier.fit(training_feat,tr_lab)\n",
    "    #pred = create_and_save_confusion_matrix(classifier, tst_features, tst_lab, species, vv,'results/phow_4_opponent/knn/','conf_mat_knn_' + str(vv) + '.jpg')\n",
    "    \n",
    "    \n",
    "    \n",
    "    #plot_and_save_knn(knnacc, knnprec, knnrec,'results/phow_4_opponent/knn/plotting_' + str(vv) + '.jpg')\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    accuracy.append(np.mean(score))\n",
    "    precision.append(np.mean(a))\n",
    "    recall.append(np.mean(b))\n",
    "    #f1score.append(np.mean(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot precision recall and accuracy \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "x1 = [200,250,300,350,400,450,500,550,600,650,700,750,800,850,900]\n",
    "plt.plot(x1, accuracy, label = \"accuracy\",color = 'r')\n",
    "plt.plot(x1,precision, label = 'precision')\n",
    "plt.plot(x1, recall, label = 'recall',color = 'g')\n",
    "plt.xticks(x1)\n",
    "plt.xlabel('number of words')\n",
    "plt.ylabel('percentage %')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.savefig('results/phow_6_opponent/total/acc_prec_rec.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [200,250,300,350,400,450,500,550,600,650,700,750,800,850,900]\n",
    "df = pd.DataFrame({\"X\":x1, \"precision\":precision,\"recall\":recall,'accuracy': accuracy})\n",
    "df.plot(x=\"X\", y=[\"precision\", \"recall\",'accuracy'], kind=\"bar\")\n",
    "plt.grid()\n",
    "plt.xlabel('number of visualwords')\n",
    "plt.ylabel('Percentate %')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('results/phow_6_opponent/total/acc_prec_rec_bar.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat,loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VARY THE GRIDSIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual = [4,6,8,12,16,32,64]\n",
    "\n",
    "precision = []\n",
    "recall = []\n",
    "accuracy = []\n",
    "f1score = []\n",
    "\n",
    "for i,vv in enumerate(visual):\n",
    "    print('-----------------------------')\n",
    "    print(vv)\n",
    "    print('------------------------------')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    trf = '../../../features_for_python_' + str(vv) + '_opponent_phow/phowf_' + str(vv) + '_500_rbf/training_features.mat'\n",
    "    trlab = '../../../features_for_python_' + str(vv) + '_opponent_phow/phowf_' + str(vv) + '_500_rbf/training_lab_features.mat'\n",
    "\n",
    "    tstf = '../../../features_for_python_' + str(vv) + '_opponent_phow/phowf_' + str(vv) + '_500_rbf/testing_features.mat'\n",
    "    tstlab = '../../../features_for_python_' + str(vv) + '_opponent_phow/phowf_' + str(vv) + '_500_rbf/testing_lab_features.mat'\n",
    "\n",
    "\n",
    "\n",
    "    training_feat,tr_lab = load_descriptor_from_matfile(trf, trlab)\n",
    "    tst_features, tst_lab = load_descriptor_from_matfile(tstf,tstlab)\n",
    "\n",
    "    tr_lab = tr_lab -1\n",
    "    tst_lab = tst_lab -1\n",
    "    \n",
    "    svm, score = search_for_best_rbf(training_feat, tr_lab, tst_features, tst_lab)\n",
    "    name = \"phow_\"+str(vv)+'_500_opponent_'\n",
    "    direc = \"results/results/phow_500/confusion_matrix/\"\n",
    "    pred = create_and_save_confusion_matrix(tst_features, tst_lab, species, vv,direc,name)\n",
    "    \n",
    "    a,b,c = calculate_and_plot_precision_recall(tst_lab, pred, species, 'results/grid_results/phow_500/precision_recall/', 'phow_' + str(vv) +'_500_opponent')\n",
    "    \n",
    "\n",
    "    \n",
    "    #accuracy.append(np.mean(score))\n",
    "    #precision.append(np.mean(a))\n",
    "    #recall.append(np.mean(b))\n",
    "    #f1score.append(np.mean(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"X\":visual, \"precision\":precision,\"recall\":recall,'accuracy': accuracy})\n",
    "df.plot(x=\"X\", y=[\"precision\", \"recall\",'accuracy'], kind=\"bar\")\n",
    "plt.grid()\n",
    "plt.xlabel('density of the grid (in pixel)')\n",
    "plt.ylabel('Percentate %')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/grid_results/phow_500/total/acc_prec_rec.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRY TO BUILD A MASK \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we want a specific svm---> take 4 grid 400 opponent\n",
    "\n",
    "trf = '../../../features_for_python_' + str(4) + '_opponent_phow/phowf_' + str(4) + '_400_rbf/training_features.mat'\n",
    "trlab = '../../../features_for_python_' + str(4) + '_opponent_phow/phowf_' + str(4) + '_400_rbf/training_lab_features.mat'\n",
    "\n",
    "tstf = '../../../features_for_python_' + str(4) + '_opponent_phow/phowf_' + str(4) + '_400_rbf/testing_features.mat'\n",
    "tstlab = '../../../features_for_python_' + str(4) + '_opponent_phow/phowf_' + str(4) + '_400_rbf/testing_lab_features.mat'\n",
    "\n",
    "training_feat,tr_lab = load_descriptor_from_matfile(trf, trlab)\n",
    "tst_features, tst_lab = load_descriptor_from_matfile(tstf,tstlab)\n",
    "tr_lab = tr_lab -1\n",
    "tst_lab = tst_lab -1\n",
    "\n",
    "svm, score = search_for_best_rbf(training_feat, tr_lab, tst_features, tst_lab)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tt = 70\n",
    "\n",
    "pred = svm.predict([tst_features[tt].reshape(-1)])[0]\n",
    "print(species[pred])\n",
    "print(species[tst_lab[tt][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = loadmat('robustness/image_0/desc/descriptors.mat')\n",
    "cr = cr['or_featureVector']\n",
    "svm.predict([cr.reshape(-1)])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = loadmat('robustness/image_3/desc/direc.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "immagini = ['original','I_90','I_180','I_270','I_g2_','I_g4_','I_g6_','I_g8_','I_g10_','I_il20_',\n",
    "           'I_il60_','I_il100_']\n",
    "\n",
    "\n",
    "imgd_dsc = {}\n",
    "imgd_dsc['original'] = 'descriptors.mat'\n",
    "imgd_dsc['I_90'] = 'I_90_descriptors.mat'\n",
    "imgd_dsc['I_180'] = 'I_180_descriptors.mat'\n",
    "imgd_dsc['I_270'] = 'I_270_descriptors.mat'\n",
    "\n",
    "imgd_dsc['I_g2_'] = 'I_g2_descriptors.mat'\n",
    "imgd_dsc['I_g4_'] = 'I_g4_descriptors.mat'\n",
    "imgd_dsc['I_g6_'] = 'I_g6_descriptors.mat'\n",
    "imgd_dsc['I_g8_'] = 'I_g8_descriptors.mat'\n",
    "imgd_dsc['I_g10_'] = 'I_g10_descriptors.mat'\n",
    "\n",
    "imgd_dsc['I_il20_'] = 'I_il20_descriptors.mat'\n",
    "imgd_dsc['I_il60_'] = 'I_il60_descriptors.mat'\n",
    "imgd_dsc['I_il100_'] = 'I_il100_descriptors.mat'\n",
    "\n",
    "\n",
    "labels_x = {}\n",
    "\n",
    "\n",
    "labels_x['original'] = 'original image'\n",
    "labels_x['I_90'] = '90° rotation'\n",
    "labels_x['I_180'] = '180° rotation'\n",
    "labels_x['I_270'] = '270° rotation'\n",
    "\n",
    "\n",
    "labels_x['I_g2_'] = 'smooth with sigma = 0.3'\n",
    "labels_x['I_g4_'] = 'smooth with sigma = 0.6'\n",
    "labels_x['I_g6_'] = 'smooth with sigma = 0.1'\n",
    "labels_x['I_g8_'] = 'smooth with sigma = 1.3'\n",
    "labels_x['I_g10_'] = 'smooth with sigma = 1.6'\n",
    "\n",
    "labels_x['I_il20_'] = 'add 20 to every pixel'\n",
    "labels_x['I_il60_'] = 'add 60 to every pixel'\n",
    "labels_x['I_il100_'] = 'add 100 to every pixel'\n",
    "\n",
    "desc_path = 'robustness/image_3/desc'\n",
    "im_pth = 'robustness/image_3/image'\n",
    "fig, m_axs = plt.subplots(3, 4, figsize = (25, 15))\n",
    "i = 0\n",
    "j = 0\n",
    "for  immg in  immagini:\n",
    "    # desc \n",
    "    descriptor_pth = os.path.join(desc_path,imgd_dsc[immg])\n",
    "    cr = loadmat(descriptor_pth)\n",
    "    if(imgd_dsc[immg] == 'descriptors.mat'):\n",
    "        cr = cr['or_featureVector']\n",
    "    else:\n",
    "        cr = cr['featureVector']     \n",
    "    prd = svm.predict([cr.reshape(-1)])[0]\n",
    "    temp = species[prd]\n",
    "    pp = os.path.join(im_pth, immg + '.jpg')\n",
    "    im = cv2.imread(pp)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    m_axs[i,j].imshow(im)\n",
    "    m_axs[i,j].set_title(labels_x[immg] + ': ' + temp,color=(\"green\" if temp=='Candelariella_xanthostigma' else \"red\"))\n",
    "    m_axs[i,j].axis('off')\n",
    "    #m_axs[i,j].set_xlabel(labels_x[im])\n",
    "    j = j + 1\n",
    "    if(j > 3):\n",
    "        i = i + 1\n",
    "        j = 0\n",
    "plt.savefig('results/robust/Candelariella_xanthostigma_robust.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VALUTAZIONE ROBUSTEZZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_right = []\n",
    "labels = []\n",
    "for i in range(tst_features.shape[0]):\n",
    "    tst = tst_features[i]\n",
    "    pred = svm.predict([tst.reshape(-1)])[0]\n",
    "    if pred == tst_lab[i][0]:\n",
    "        temp = species[tst_lab[i][0]] + '_' + str(i)\n",
    "        feat_right.append(i+1)\n",
    "        labels.append(tst_lab[i][0])\n",
    "\n",
    "c = {'a': feat_right, 'b': labels}\n",
    "from scipy.io import savemat\n",
    "savemat(\"images_to_be_augmented.mat\",c)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feat_right)/tst_features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predicted_mask(c):\n",
    "    mask = np.zeros((10,10))\n",
    "    for i in range(c.shape[0]):\n",
    "        for j in range(c.shape[1]):\n",
    "            r = svm.predict([c[i,j,:]])\n",
    "            mask[i,j] = r[0]\n",
    "    return mask\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = create_predicted_mask(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pth_imm = '../../../images_matlab_test/text_image_N1'\n",
    "#immagine = cv2.imread(pth_imm + '/text_image_N1.jpg')\n",
    "#immagine = cv2.cvtColor(immagine, cv2.COLOR_RGB2BGR)\n",
    "#plt.imshow(immagine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dscpth = os.path.join(pth_imm,'dsc')\n",
    "dsc_list = os.listdir(dscpth )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    for j in range(7):\n",
    "        stringa = 'crops_' + str(i) + '_' + str(j) + '.mat'\n",
    "        descrittore = os.path.join(dscpth,stringa)\n",
    "        desc = loadmat(descrittore)\n",
    "        desc = desc['featureVector']\n",
    "        desc = desc.reshape(-1)\n",
    "        print(svm.predict([desc]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTHER STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = loadmat('scale_robustness/features_400.mat')\n",
    "dd = loadmat('scale_robustness/labels.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features= cc['feat']\n",
    "labs = dd['labs']\n",
    "labs = labs -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(features.shape[0]):\n",
    "    ft = features[i]\n",
    "    lab = labs[i][0]\n",
    "    print('.................')\n",
    "    print( svm.predict([ft.reshape(-1)])[0] == lab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(training_feat)\n",
    "\n",
    "X_train = scaler.transform(training_feat)\n",
    "X_test = scaler.transform(tst_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_and_calculate_accuracy(train_features,train_lab,test_features,test_lab): \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_features)\n",
    "\n",
    "    X_train = scaler.transform(train_features)\n",
    "    X_test = scaler.transform(test_features)\n",
    "    clc = []\n",
    "    acc = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    for i in range(1,51):\n",
    "        classifier = KNeighborsClassifier(n_neighbors=i) \n",
    "        classifier.fit(X_train, train_lab)\n",
    "        clc.append(classifier)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        acc_temp = 0\n",
    "        total = y_pred.shape[0]\n",
    "        for j in range(y_pred.shape[0]):\n",
    "            if y_pred[j]==test_lab[j]:\n",
    "                acc_temp = acc_temp + 1\n",
    "        precision, recall, fbeta, support = precision_recall_fscore_support(tst_lab, y_pred)\n",
    "        prec.append(np.mean(precision))\n",
    "        rec.append(np.mean(recall))\n",
    "        acc.append(acc_temp/total)\n",
    "    return acc, prec, rec,clc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc,prec, rec, classif = train_model_and_calculate_accuracy(training_feat, tr_lab, tst_features, tst_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x1 = np.arange(1,51)\n",
    "plt.plot(x1, acc, label = \"accuracy\",color = 'r')\n",
    "plt.plot(x1,prec, label = 'precision')\n",
    "plt.plot(x1, rec, label = 'recall',color = 'g')\n",
    "plt.xlabel('number of neighbors')\n",
    "plt.ylabel('percentage (%)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('results/grid_results/k-nearest_neighbor_total.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda10374d56d606404d89697440b2a570f1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
