{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/Users/admin/Desktop/tesi/Thesis/')\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "import sklearn.metrics as skmetrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from handcrafted_descriptors.grid_classification import utils\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def load_descriptor_from_matfile(ft_path,lab_path):\n",
    "    feat = loadmat(ft_path)\n",
    "    feat = feat['dsc']\n",
    "    lab = loadmat(lab_path)\n",
    "    lab = lab['lab']\n",
    "    return feat, lab\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_and_plot_precision_recall(tst_lab, pred, species, directory, string):\n",
    "    precision, recall, fbeta, support = precision_recall_fscore_support(tst_lab, pred)\n",
    "    \n",
    "    df = pd.DataFrame({\"X\":species, \"precision\":precision,\"recall\":recall,'f1score': fbeta})\n",
    "    df.plot(x=\"X\", y=[\"precision\", \"recall\",'f1score'], kind=\"bar\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(directory +'precision_recall_class4class'+string+'.jpg')\n",
    "    return np.mean(precision), np.mean(recall), np.mean(fbeta)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_model_and_calculate_accuracy(train_features,train_lab,test_features,test_lab): \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_features)\n",
    "\n",
    "    X_train = scaler.transform(train_features)\n",
    "    X_test = scaler.transform(test_features)\n",
    "    clc = []\n",
    "    acc = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    for i in range(1,51):\n",
    "        classifier = KNeighborsClassifier(n_neighbors=i) \n",
    "        classifier.fit(X_train, train_lab)\n",
    "        clc.append(classifier)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        acc_temp = 0\n",
    "        total = y_pred.shape[0]\n",
    "        for j in range(y_pred.shape[0]):\n",
    "            if y_pred[j]==test_lab[j]:\n",
    "                acc_temp = acc_temp + 1\n",
    "        precision, recall, fbeta, support = precision_recall_fscore_support(test_lab, y_pred,zero_division=0)\n",
    "        prec.append(np.mean(precision))\n",
    "        rec.append(np.mean(recall))\n",
    "        acc.append(acc_temp/total)\n",
    "    return acc, prec, rec,clc \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def evaluated_prediction(pred,test_lab,lab ):\n",
    "    \"\"\"\n",
    "    Function which evaluate quality of prdiction of linear svm, calculating TP,FP,FN,TN\n",
    "\n",
    "    Input pred = prediction\n",
    "    Input test_lab = labels\n",
    "    Input num_classes(15) = number of classes\n",
    "    Input lab = name of classes\n",
    "\n",
    "    Output  res = dataframe with all these values\n",
    "    \"\"\"\n",
    "    num_classes = len(lab)\n",
    "    tp = []\n",
    "    fp = []\n",
    "    fn = []\n",
    "    tn = []\n",
    "    for i in range(num_classes):\n",
    "        tp_temp = 0\n",
    "        fp_temp = 0\n",
    "        fn_temp = 0\n",
    "        tn_temp = 0\n",
    "        for j in range(len(pred)):\n",
    "            if(pred[j]==lab[i] and test_lab[j]==lab[i]):\n",
    "                tp_temp = tp_temp + 1\n",
    "            if(pred[j]==lab[i] and test_lab[j]!=lab[i]):\n",
    "                fp_temp = fp_temp + 1\n",
    "            if(pred[j]!=lab[i] and test_lab[j]==lab[i]):\n",
    "                fn_temp = fn_temp + 1\n",
    "            if(pred[j]!=lab[i] and test_lab[j]!=lab[i]):\n",
    "\n",
    "                tn_temp = tn_temp +1\n",
    "        tp.append(tp_temp)\n",
    "        fp.append(fp_temp)\n",
    "        fn.append(fn_temp)\n",
    "        tn.append(tn_temp)\n",
    "    data = {'labels':lab , 'True positive':tp,'True negative':tn,'False positive':fp,'False negative':fn}\n",
    "    res = pd.DataFrame(data, columns = ['labels','True positive','True negative','False positive','False negative'])\n",
    "    return res\n",
    "\n",
    "\n",
    "def build_confusion_matrix(df,pred,test_labels,lab):\n",
    "    \"\"\"\n",
    "    Function tu construct confusion matrix\n",
    "    \"\"\"\n",
    "    num_classes = len(lab)\n",
    "    cm = np.zeros((num_classes,num_classes))\n",
    "    # insert true positive on the diagonal\n",
    "    for i in range(num_classes):\n",
    "        cm[i,i] = df.loc[i]['True positive']\n",
    "    for i in range(num_classes): # lavoro sulle classes true\n",
    "        for j in range(num_classes): #lavoro su classes predicted\n",
    "            temp = 0\n",
    "            for k in range(len(test_labels)):\n",
    "                if(test_labels[k]==lab[i] and pred[k]==lab[j]):\n",
    "                    temp = temp +1\n",
    "            cm[i,j]=temp\n",
    "    return cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_best_rbf(training_feat, tr_lab, tst_features, tst_lab):\n",
    "    param_grid = {'C': [ 1e0, 1e1, 1e2,1e3], 'gamma': [   0.01, 0.1,1]}\n",
    "    clf0 = GridSearchCV(SVC(kernel='rbf'), param_grid)\n",
    "    svc = clf0.fit(training_feat, tr_lab)\n",
    "    print(\"Best estimator found by grid search : \", clf0.best_estimator_)\n",
    "    y_pred = clf0.predict(tst_features)\n",
    "    print('Accuracy score :', skmetrics.accuracy_score(y_pred, tst_lab))\n",
    "    return clf0,skmetrics.accuracy_score(y_pred, tst_lab)\n",
    "\n",
    "def search_for_best_poly(training_feat, tr_lab, tst_features, tst_lab):\n",
    "    param_grid = {'degree':[2,3,4,5],'C': [ 1e0, 1e1, 1e2,1e3], 'gamma': [ 0.001, 0.01, 0.1,1]}\n",
    "    clf0 = GridSearchCV(SVC(kernel='poly'), param_grid)\n",
    "    svc = clf0.fit(training_feat, tr_lab)\n",
    "    print(\"Best estimator found by grid search : \", clf0.best_estimator_)\n",
    "    y_pred = clf0.predict(tst_features)\n",
    "    print('Accuracy score :', skmetrics.accuracy_score(y_pred, tst_lab))\n",
    "    return clf0, skmetrics.accuracy_score(y_pred, tst_lab)\n",
    "\n",
    "def create_and_save_confusion_matrix(model, tst_features, tst_lab, species,director, name ):\n",
    "    pred = model.predict(tst_features)\n",
    "    df = utils.evaluated_prediction(pred, tst_lab, species)\n",
    "    cm = utils.build_confusion_matrix(df, pred, tst_lab,species)\n",
    "    utils.plot_confusion_matrix(cm,species,name,director,normalize=True,title='Confusion matrix')\n",
    "    plt.close()\n",
    "    return pred\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_and_save_knn(acc,prec,rec,direct):\n",
    "    x1 = np.arange(1,51)\n",
    "    plt.plot(x1, acc, label = \"accuracy\",color = 'r')\n",
    "    plt.plot(x1,prec, label = 'precision')\n",
    "    plt.plot(x1, rec, label = 'recall',color = 'g')\n",
    "    plt.xlabel('number of neighbors')\n",
    "    plt.ylabel('percentage (%)')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(direct)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = ['Arthonia_radiata','Caloplaca_cerina','Candelariella_reflexa','Candelariella_xanthostigma','Chrysothrix_candelaris','Flavoparmelia_caperata','Gyalolechia_flavorubescens','Hyperphyscia_adglutinata'\n",
    "        ,'Lecanora_argentata','Lecanora_chlarotera','Lecidella_elaeochroma','Melanelixia_glabratula'\n",
    "        ,'Phaeophyscia_orbicularis','Physcia_biziana','Physconia_grisea','Ramalina_farinacea','Ramalina_fastigiata','Xanthomendoza_fallax','Xanthomendoza_fulva','flavoparmenia_soredians']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "(1,1)\n",
      "-------------------\n",
      "start rbf\n",
      "Best estimator found by grid search :  SVC(C=1000.0, gamma=1)\n",
      "Accuracy score : 0.5233853006681515\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-621955eaffa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'start rbf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0msvm\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mscore_rbf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_for_best_rbf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_lab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtst_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtst_lab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mcreate_and_save_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtst_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtst_lab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdirector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_and_plot_precision_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst_lab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirector_pra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_pra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# claculate precision and recall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vw' is not defined"
     ]
    }
   ],
   "source": [
    "vector = ['1','2','3','4','5','6','7','8']\n",
    "\n",
    "\n",
    "acc_radial = {}\n",
    "acc_poly = {}\n",
    "#acc_1nn = {}\n",
    "\n",
    "for i,rot in enumerate(vector):\n",
    "    for j,scale in enumerate(vector):\n",
    "        print('------------------')\n",
    "        print('(' + rot + ',' + scale + ')')\n",
    "        print('-------------------')\n",
    "        \n",
    "        #create directories \n",
    "        director = 'result_gabor/confusion_matrix/'\n",
    "        director_pra = 'result_gabor/pra/'\n",
    "        name = 'cm_'+ rot + '_' + scale\n",
    "        name_pra = 'pra_'+ rot + '_' + scale\n",
    "        \n",
    "        string_training = 'dsc/' + str(rot) + '_' + str(scale) + '_' + 'train_descriptors.mat'\n",
    "        string_training_label = 'dsc/' + str(rot) + '_' + str(scale) + '_' + 'train_labels.mat'       \n",
    "        string_testing = 'dsc/' + str(rot) + '_' + str(scale) + '_' + 'test_descriptors.mat'\n",
    "        string_testing_label = 'dsc/' + str(rot) + '_' + str(scale) + '_' + 'test_labels.mat'\n",
    "        \n",
    "        training_feat,tr_lab = load_descriptor_from_matfile(string_training, string_training_label)\n",
    "        tst_features, tst_lab = load_descriptor_from_matfile(string_testing,string_testing_label)\n",
    "        tr_lab = tr_lab -1\n",
    "        tst_lab = tst_lab -1 \n",
    "        print('start rbf')\n",
    "        svm ,score_rbf = search_for_best_rbf(training_feat, tr_lab.reshape(-1), tst_features, tst_lab)\n",
    "        create_and_save_confusion_matrix(svm, tst_features, tst_lab, species,director, name)\n",
    "        pred = calculate_and_plot_precision_recall(tst_lab, pred, species, director_pra, name_pra)\n",
    "        # claculate precision and recall \n",
    "        #print('start poly')\n",
    "        #svm ,score_poly = search_for_best_poly(training_feat, tr_lab.reshape(-1), tst_features, tst_lab)\n",
    "        #print('start 1nn')\n",
    "        #acc, prec, rec,clc  = train_model_and_calculate_accuracy(training_feat, tr_lab.reshape(-1), tst_features, tst_lab.reshape(-1))\n",
    "        acc_radial['(' + str(rot) + ',' + str(scale) + ')'] = score_rbf\n",
    "        #acc_poly['(' + str(rot) + ',' + str(scale) + ')'] = score_poly\n",
    "        #acc_1nn['(' + str(rot) + ',' + str(scale) + ')'] = acc[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_feat,tr_lab = load_descriptor_from_matfile('dsc/training_descriptors.mat', 'dsc/training_labels.mat')\n",
    "tst_features, tst_lab = load_descriptor_from_matfile('dsc/test_descriptors.mat','dsc/test_labels.mat')\n",
    "tr_lab = tr_lab -1\n",
    "tst_lab = tst_lab -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm ,score = search_for_best_rbf(training_feat, tr_lab.reshape(-1), tst_features, tst_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm ,score = search_for_best_poly(training_feat, tr_lab.reshape(-1), tst_features, tst_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "acc, prec, rec,clc  = train_model_and_calculate_accuracy(training_feat, tr_lab.reshape(-1), tst_features, tst_lab.reshape(-1))\n",
    "plot_and_save_knn(acc,prec,rec,'knn_gabor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_plot_precision_recall(tst_lab, pred, species, directory, string):\n",
    "    precision, recall, fbeta, support = precision_recall_fscore_support(tst_lab, pred)\n",
    "    \n",
    "    df = pd.DataFrame({\"X\":species, \"precision\":precision,\"recall\":recall,'f1score': fbeta})\n",
    "    df.plot(x=\"X\", y=[\"precision\", \"recall\",'f1score'], kind=\"bar\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(directory +'precision_recall_class4class'+string+'.jpg')\n",
    "    return np.mean(precision), np.mean(recall), np.mean(fbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label = np.arange(0,20)\n",
    "\n",
    "linear_score = svm.score(tst_features,tst_lab)\n",
    "pred = svm.predict(tst_features)\n",
    "df = utils.evaluated_prediction(pred, tst_lab, species)\n",
    "cm = utils.build_confusion_matrix(df, pred, tst_lab,species)\n",
    "fig=plt.figure(figsize=(30, 15))\n",
    "utils.plot_confusion_matrix(cm,species,\"conf\",\"results_gabor/\",normalize=True,title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_and_plot_precision_recall(tst_lab, pred, species, 'results_gabor/', 'pra.jpg')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda10374d56d606404d89697440b2a570f1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
