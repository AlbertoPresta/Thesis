{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/Users/admin/Desktop/tesi/Thesis/')\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "import sklearn.metrics as skmetrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from handcrafted_descriptors.grid_classification import utils\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "species = ['Arthonia_radiata','Caloplaca_cerina','Candelariella_reflexa','Candelariella_xanthostigma','Chrysothrix_candelaris','Flavoparmelia_caperata','Gyalolechia_flavorubescens','Hyperphyscia_adglutinata'\n",
    "        ,'Lecanora_argentata','Lecanora_chlarotera','Lecidella_elaeochroma','Melanelixia_glabratula'\n",
    "        ,'Phaeophyscia_orbicularis','Physcia_biziana','Physconia_grisea','Ramalina_farinacea','Ramalina_fastigiata','Xanthomendoza_fallax','Xanthomendoza_fulva','flavoparmenia_soredians']\n",
    "\n",
    "def load_descriptor_from_matfile(ft_path,lab_path):\n",
    "    feat = loadmat(ft_path)\n",
    "    feat = feat['dsc']\n",
    "    lab = loadmat(lab_path)\n",
    "    lab = lab['lab']\n",
    "    return feat, lab\n",
    "\n",
    "\n",
    "\n",
    "def gabor_kernel(u,v,vec):\n",
    "\n",
    "    m = u.shape[0]\n",
    "    res = 0\n",
    "    for i in range(0,m,2):\n",
    "        mu_u = u[i]\n",
    "        mu_v = v[i]\n",
    "\n",
    "        sig_u = u[i+1]\n",
    "        sig_v = v[i+1]\n",
    "\n",
    "        mu_sum = np.abs((mu_u - mu_v)/vec[i])\n",
    "        sig_sum = np.abs((sig_u - sig_v)/vec[i+1])\n",
    "\n",
    "        res += (mu_sum + sig_sum)\n",
    "    res = np.exp(-res)\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def gabor_distance(u,v,vec):\n",
    "    m = u.shape[0]\n",
    "    res = 0\n",
    "    for i in range(0,m,2):\n",
    "        mu_u = u[i]\n",
    "        mu_v = v[i]\n",
    "\n",
    "        sig_u = u[i+1]\n",
    "        sig_v = v[i+1]\n",
    "\n",
    "        mu_sum = np.abs((mu_u - mu_v)/vec[i])\n",
    "        sig_sum = np.abs((sig_u - sig_v)/vec[i+1])\n",
    "\n",
    "        res += (mu_sum + sig_sum)\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_gram_matrix(data,kernel):\n",
    "    samples,_ = np.shape(data)\n",
    "    print(samples)\n",
    "    vec= np.std(data,axis = 0)\n",
    "    matrix = np.zeros((samples,samples))\n",
    "    for r in range(samples):\n",
    "        print(r)\n",
    "        for c in range(r,samples):\n",
    "            tmp = kernel(data[r],data[c],vec)\n",
    "            matrix[r,c] = tmp\n",
    "            matrix[c,r] = tmp\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def define_and_train_svm(tr_feature, tr_lab, kernel_type, distance = None):\n",
    "    if distance == None:\n",
    "        print('here')\n",
    "        svc  = OneVsRestClassifier(SVC(kernel = kernel_type,gamma = 'scale'),n_jobs = -1)\n",
    "        svc = svc.fit(tr_feature, tr_lab)\n",
    "        return svc, 0, np.zeros(tr_feature.shape[0])\n",
    "    else:\n",
    "        gram=  compute_gram_matrix(tr_feature,distance)\n",
    "        mean = np.mean(gram[np.triu_indices(np.shape(tr_feature)[0])])\n",
    "        gram = np.exp(-(gram)) # generalized Gaussian kernel\n",
    "        svc  = OneVsRestClassifier(SVC(kernel = 'precomputed'),n_jobs = -1)\n",
    "        svc = svc.fit(gram,np.array(tr_lab))\n",
    "        return svc, mean,gram\n",
    "\n",
    "def test_accuracy(test_features,features,kernel,vec, test_label,svc):\n",
    "    num_objects = features.shape[0]\n",
    "    print(num_objects)\n",
    "    print(test_features.shape[0])\n",
    "    res = []\n",
    "    prediction = []\n",
    "    for i,ft in enumerate(test_features):\n",
    "        print(i)\n",
    "\n",
    "        pred = svc.predict(np.array([kernel(ft, features[num, :], vec) for num in range(num_objects)]).reshape(1, -1))\n",
    "        prediction.append(pred[0])\n",
    "        #print(i,\": \",pred,\" : \",test_label[i])\n",
    "        if(pred==test_label[i]):\n",
    "            res.append(1)\n",
    "        else:\n",
    "            res.append(0)\n",
    "\n",
    "    res = np.array(res).reshape(-1)\n",
    "    return np.sum(res)/res.shape, np.array(prediction)\n",
    "\n",
    "\n",
    "\n",
    "def train_model_and_calculate_accuracy(train_features,train_lab,test_features,test_lab): \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_features)\n",
    "\n",
    "    X_train = scaler.transform(train_features)\n",
    "    X_test = scaler.transform(test_features)\n",
    "    clc = []\n",
    "    acc = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    for i in range(1,51):\n",
    "        classifier = KNeighborsClassifier(n_neighbors=i) \n",
    "        classifier.fit(X_train, train_lab)\n",
    "        clc.append(classifier)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        acc_temp = 0\n",
    "        total = y_pred.shape[0]\n",
    "        for j in range(y_pred.shape[0]):\n",
    "            if y_pred[j]==test_lab[j]:\n",
    "                acc_temp = acc_temp + 1\n",
    "        precision, recall, fbeta, support = precision_recall_fscore_support(test_lab, y_pred,zero_division=0)\n",
    "        prec.append(np.mean(precision))\n",
    "        rec.append(np.mean(recall))\n",
    "        acc.append(acc_temp/total)\n",
    "    return acc, prec, rec,clc \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def evaluated_prediction(pred,test_lab,lab ):\n",
    "    \"\"\"\n",
    "    Function which evaluate quality of prdiction of linear svm, calculating TP,FP,FN,TN\n",
    "\n",
    "    Input pred = prediction\n",
    "    Input test_lab = labels\n",
    "    Input num_classes(15) = number of classes\n",
    "    Input lab = name of classes\n",
    "\n",
    "    Output  res = dataframe with all these values\n",
    "    \"\"\"\n",
    "    num_classes = len(lab)\n",
    "    tp = []\n",
    "    fp = []\n",
    "    fn = []\n",
    "    tn = []\n",
    "    for i in range(num_classes):\n",
    "        tp_temp = 0\n",
    "        fp_temp = 0\n",
    "        fn_temp = 0\n",
    "        tn_temp = 0\n",
    "        for j in range(len(pred)):\n",
    "            if(pred[j]==lab[i] and test_lab[j]==lab[i]):\n",
    "                tp_temp = tp_temp + 1\n",
    "            if(pred[j]==lab[i] and test_lab[j]!=lab[i]):\n",
    "                fp_temp = fp_temp + 1\n",
    "            if(pred[j]!=lab[i] and test_lab[j]==lab[i]):\n",
    "                fn_temp = fn_temp + 1\n",
    "            if(pred[j]!=lab[i] and test_lab[j]!=lab[i]):\n",
    "\n",
    "                tn_temp = tn_temp +1\n",
    "        tp.append(tp_temp)\n",
    "        fp.append(fp_temp)\n",
    "        fn.append(fn_temp)\n",
    "        tn.append(tn_temp)\n",
    "    data = {'labels':lab , 'True positive':tp,'True negative':tn,'False positive':fp,'False negative':fn}\n",
    "    res = pd.DataFrame(data, columns = ['labels','True positive','True negative','False positive','False negative'])\n",
    "    return res\n",
    "\n",
    "\n",
    "def build_confusion_matrix(df,pred,test_labels,lab):\n",
    "    \"\"\"\n",
    "    Function tu construct confusion matrix\n",
    "    \"\"\"\n",
    "    num_classes = len(lab)\n",
    "    cm = np.zeros((num_classes,num_classes))\n",
    "    # insert true positive on the diagonal\n",
    "    for i in range(num_classes):\n",
    "        cm[i,i] = df.loc[i]['True positive']\n",
    "    for i in range(num_classes): # lavoro sulle classes true\n",
    "        for j in range(num_classes): #lavoro su classes predicted\n",
    "            temp = 0\n",
    "            for k in range(len(test_labels)):\n",
    "                if(test_labels[k]==lab[i] and pred[k]==lab[j]):\n",
    "                    temp = temp +1\n",
    "            cm[i,j]=temp\n",
    "    return cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_best_rbf(training_feat, tr_lab, tst_features, tst_lab):\n",
    "    param_grid = {'C': [ 1e0, 1e1, 1e2,1e3], 'gamma': [   0.01, 0.1,1]}\n",
    "    clf0 = GridSearchCV(SVC(kernel='rbf'), param_grid)\n",
    "    svc = clf0.fit(training_feat, tr_lab)\n",
    "    print(\"Best estimator found by grid search : \", clf0.best_estimator_)\n",
    "    y_pred = clf0.predict(tst_features)\n",
    "    print('Accuracy score :', skmetrics.accuracy_score(y_pred, tst_lab))\n",
    "    return clf0,skmetrics.accuracy_score(y_pred, tst_lab)\n",
    "\n",
    "def search_for_best_poly(training_feat, tr_lab, tst_features, tst_lab):\n",
    "    param_grid = {'degree':[2,3,4,5],'C': [ 1e0, 1e1, 1e2,1e3], 'gamma': [ 0.001, 0.01, 0.1,1]}\n",
    "    clf0 = GridSearchCV(SVC(kernel='poly'), param_grid)\n",
    "    svc = clf0.fit(training_feat, tr_lab)\n",
    "    print(\"Best estimator found by grid search : \", clf0.best_estimator_)\n",
    "    y_pred = clf0.predict(tst_features)\n",
    "    print('Accuracy score :', skmetrics.accuracy_score(y_pred, tst_lab))\n",
    "    return clf0, skmetrics.accuracy_score(y_pred, tst_lab)\n",
    "\n",
    "def create_and_save_confusion_matrix(model, tst_features, tst_lab, species, vw,director, name ):\n",
    "    pred = model.predict(tst_features)\n",
    "    df = utils.evaluated_prediction(pred, tst_lab, species)\n",
    "    cm = utils.build_confusion_matrix(df, pred, tst_lab,species)\n",
    "    fig=plt.figure(figsize=(30, 15))\n",
    "    utils.plot_confusion_matrix(cm,species,name,director,normalize=True,title='Confusion matrix')\n",
    "    plt.close()\n",
    "    return pred\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_and_save_knn(acc,prec,rec,direct):\n",
    "    x1 = np.arange(1,51)\n",
    "    plt.plot(x1, acc, label = \"accuracy\",color = 'r')\n",
    "    plt.plot(x1,prec, label = 'precision')\n",
    "    plt.plot(x1, rec, label = 'recall',color = 'g')\n",
    "    plt.xlabel('number of neighbors')\n",
    "    plt.ylabel('percentage (%)')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(direct)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = ['1','2','3','4','5','6','7','8']\n",
    "\n",
    "\n",
    "acc_radial = {}\n",
    "#acc_poly = {}\n",
    "acc_1nn = {}\n",
    "\n",
    "for i,rot in enumerate(vector):\n",
    "    for j,scale in enumerate(vector):\n",
    "        print('------------------')\n",
    "        print('(' + rot + ',' + scale + ')')\n",
    "        print('-------------------')\n",
    "        string_training = 'dsc/' + str(rot) + '_' + str(scale) + '_' + 'train_descriptors.mat'\n",
    "        string_training_label = 'dsc/' + str(rot) + '_' + str(scale) + '_' + 'train_labels.mat'       \n",
    "        string_testing = 'dsc/' + str(rot) + '_' + str(scale) + '_' + 'test_descriptors.mat'\n",
    "        string_testing_label = 'dsc/' + str(rot) + '_' + str(scale) + '_' + 'test_labels.mat'\n",
    "        \n",
    "        training_feat,tr_lab = load_descriptor_from_matfile(string_training, string_training_label)\n",
    "        tst_features, tst_lab = load_descriptor_from_matfile(string_testing,string_testing_label)\n",
    "        tr_lab = tr_lab -1\n",
    "        tst_lab = tst_lab -1 \n",
    "        #print('start rbf')\n",
    "        #svm ,score_rbf = search_for_best_rbf(training_feat, tr_lab.reshape(-1), tst_features, tst_lab)\n",
    "        #print('start poly')\n",
    "        #svm ,score_poly = search_for_best_poly(training_feat, tr_lab.reshape(-1), tst_features, tst_lab)\n",
    "        print('start 1nn')\n",
    "        acc, prec, rec,clc  = train_model_and_calculate_accuracy(training_feat, tr_lab.reshape(-1), tst_features, tst_lab.reshape(-1))\n",
    "        #acc_radial['(' + str(rot) + ',' + str(scale) + ')'] = score_rbf\n",
    "        #acc_poly['(' + str(rot) + ',' + str(scale) + ')'] = score_poly\n",
    "        acc_1nn['(' + str(rot) + ',' + str(scale) + ')'] = acc[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_feat,tr_lab = load_descriptor_from_matfile('dsc/training_descriptors.mat', 'dsc/training_labels.mat')\n",
    "tst_features, tst_lab = load_descriptor_from_matfile('dsc/test_descriptors.mat','dsc/test_labels.mat')\n",
    "tr_lab = tr_lab -1\n",
    "tst_lab = tst_lab -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm ,score = search_for_best_rbf(training_feat, tr_lab.reshape(-1), tst_features, tst_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm ,score = search_for_best_poly(training_feat, tr_lab.reshape(-1), tst_features, tst_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "acc, prec, rec,clc  = train_model_and_calculate_accuracy(training_feat, tr_lab.reshape(-1), tst_features, tst_lab.reshape(-1))\n",
    "plot_and_save_knn(acc,prec,rec,'knn_gabor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_plot_precision_recall(tst_lab, pred, species, directory, string):\n",
    "    precision, recall, fbeta, support = precision_recall_fscore_support(tst_lab, pred)\n",
    "    \n",
    "    df = pd.DataFrame({\"X\":species, \"precision\":precision,\"recall\":recall,'f1score': fbeta})\n",
    "    df.plot(x=\"X\", y=[\"precision\", \"recall\",'f1score'], kind=\"bar\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(directory +'precision_recall_class4class'+string+'.jpg')\n",
    "    return np.mean(precision), np.mean(recall), np.mean(fbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label = np.arange(0,20)\n",
    "\n",
    "linear_score = svm.score(tst_features,tst_lab)\n",
    "pred = svm.predict(tst_features)\n",
    "df = utils.evaluated_prediction(pred, tst_lab, species)\n",
    "cm = utils.build_confusion_matrix(df, pred, tst_lab,species)\n",
    "fig=plt.figure(figsize=(30, 15))\n",
    "utils.plot_confusion_matrix(cm,species,\"conf\",\"results_gabor/\",normalize=True,title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_and_plot_precision_recall(tst_lab, pred, species, 'results_gabor/', 'pra.jpg')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda10374d56d606404d89697440b2a570f1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
