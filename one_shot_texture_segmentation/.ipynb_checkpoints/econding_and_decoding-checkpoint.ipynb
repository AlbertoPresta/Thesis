{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape, Layer\n",
    "from keras.layers import Conv2D, Conv2DTranspose\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img, reference =  'im'):\n",
    "    vgg16_model = None \n",
    "    if(reference == 'im'):\n",
    "        vgg16_model = VGG16(include_top=False, weights='imagenet',input_shape = (256,256,3),pooling = None)\n",
    "    elif(reference == 'ref'):\n",
    "        vgg16_model = VGG16(include_top=False, weights='imagenet',input_shape = (64,64,3),pooling = None)\n",
    "    else:\n",
    "        raise Exception(\"Input is not valid\")\n",
    "    res = []\n",
    "    conv1_1 = Model(inputs=vgg16_model.input, outputs=vgg16_model.get_layer('block1_conv1').output)\n",
    "    conv2_1 = Model(inputs=vgg16_model.input, outputs=vgg16_model.get_layer('block2_conv1').output)\n",
    "    conv3_1 = Model(inputs=vgg16_model.input, outputs=vgg16_model.get_layer('block3_conv1').output)\n",
    "    conv4_1 = Model(inputs=vgg16_model.input, outputs=vgg16_model.get_layer('block4_conv1').output)\n",
    "    conv5_1 = Model(inputs=vgg16_model.input, outputs=vgg16_model.get_layer('block5_conv1').output)\n",
    "\n",
    "    conv_layers = []\n",
    "    conv_layers.extend((conv1_1,conv2_1,conv3_1,conv4_1,conv5_1))\n",
    "    if(reference == 'im'):\n",
    "        #img = image.load_img(img, target_size=(256, 256))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        res = []\n",
    "        for conv in conv_layers:       \n",
    "            res.append(conv.predict(x)[0,:,:,:])\n",
    "        return np.array(res)\n",
    "    \n",
    "    elif(reference == 'ref'):\n",
    "        #img = image.load_img(img_path, target_size=(64, 64))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        res = []\n",
    "        for conv in conv_layers:       \n",
    "            res.append(conv.predict(x)[0,:,:,:])\n",
    "        return np.array(res)\n",
    "            \n",
    "    else:\n",
    "        raise Exception(\"Input is not valid\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def resblock(input_filt, filt, input_sh, name ):\n",
    "    first_conv = tf.keras.layers.Conv2D(filters=filt,kernel_size=3,padding = 'same',activation='relu',input_shape= input_sh, name = name[0])(input_filt)\n",
    "    second_conv = tf.keras.layers.Conv2D(filters=filt,kernel_size=3,padding = 'same',activation='relu',input_shape= input_sh, name = name[1])(first_conv)\n",
    "    third_conv = tf.keras.layers.Conv2D(filters=filt,kernel_size=3,padding = 'same',input_shape= input_sh, name = name[2])(second_conv)\n",
    "    return third_conv \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg16_model_64 = VGG16(include_top=False, weights='imagenet',input_shape = (64,64,3),pooling = None)\n",
    "#vgg16_model_256 = VGG16(include_top=False, weights='imagenet',input_shape = (256,256,3),pooling = None)\n",
    "\n",
    "#Â write a class which calculates features of vgg \n",
    "\n",
    "class featuring_layer(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, image_dim):\n",
    "        super(featuring_layer, self).__init__()\n",
    "        self.image_dim = image_dim\n",
    "        \n",
    "        \n",
    "    def call(self, inputs, ref ): \n",
    "        res = extract_features(inputs, reference = ref)\n",
    "        return res[0], res[1], res[2], res[3], res[4]\n",
    "        \n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONV5_1_SHAPE = (16, 16, 512)\n",
    "CONV4_1_SHAPE = (32, 32, 512)\n",
    "CONV3_1_SHAPE = (64,64,256)\n",
    "CONV2_1_SHAPE = (128,128,128)\n",
    "CONV1_1_SHAPE = (256,256,64)\n",
    "\n",
    "dim_im = [CONV5_1_SHAPE,CONV4_1_SHAPE,CONV3_1_SHAPE,CONV2_1_SHAPE,CONV1_1_SHAPE]\n",
    "\n",
    "############################################\n",
    "\n",
    "\n",
    "CONV5_1_SHAPE_REF = (4, 4, 512)\n",
    "CONV4_1_SHAPE_REF = (8, 8, 512)\n",
    "CONV3_1_SHAPE_REF = (16,16,256)\n",
    "CONV2_1_SHAPE_REF = (32,32,128)\n",
    "CONV1_1_SHAPE_REF = (64,64,64)\n",
    "\n",
    "\n",
    "dim_ref = [CONV5_1_SHAPE_REF,CONV4_1_SHAPE_REF,CONV3_1_SHAPE_REF,CONV2_1_SHAPE_REF,CONV1_1_SHAPE_REF]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 pre-trained network\n",
    "\n",
    "Download the pre-trained VGG16 neural nework, without the top (Dense) part, which is useless for our purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# point 1\n",
    "\n",
    "Extract features that we need for encoding system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(texture, ref):\n",
    "    texture = tf.nn.l2_normalize(texture, 3)\n",
    "    ref = tf.nn.l2_normalize(ref, 3)\n",
    "    cor =  tf.nn.conv2d(texture, ref, [1,1,1,1], padding='SAME', name='correlation')\n",
    "    cor = tf.math.reduce_sum(cor, axis=3, keepdims=True, name=None)\n",
    "    return cor\n",
    "\n",
    "\n",
    "def encoder(dimension):\n",
    "    if(len(dimension)!=5):\n",
    "        raise Exception(\"Input is not valid\")\n",
    "    \n",
    "    CONV5_1_SHAPE = dimension[0]\n",
    "    CONV4_1_SHAPE = dimension[1]\n",
    "    CONV3_1_SHAPE = dimension[2]\n",
    "    CONV2_1_SHAPE = dimension[3]\n",
    "    CONV1_1_SHAPE = dimension[4]\n",
    "    \n",
    "\n",
    "    \n",
    "    feature_conv5 = tf.keras.layers.Input(shape=CONV5_1_SHAPE, name = 'vgg_conv5.1_feature')\n",
    "    feature_conv4 = tf.keras.layers.Input(shape=CONV4_1_SHAPE,name = 'vgg_conv4.1_feature')\n",
    "    feature_conv3 = tf.keras.layers.Input(shape=CONV3_1_SHAPE,name = 'vgg_conv3.1_feature')\n",
    "    feature_conv2 = tf.keras.layers.Input(shape= CONV2_1_SHAPE,name = 'vgg_conv2.1_feature')\n",
    "    feature_conv1 = tf.keras.layers.Input(shape= CONV1_1_SHAPE,name = 'vgg_conv1.1_feature')\n",
    "    \n",
    "    \n",
    "    \n",
    "    #first 1x1 convolutional block\n",
    "\n",
    "    one_one_conv = tf.keras.layers.Conv2D(filters=512,kernel_size=1,padding = 'same',activation='relu',input_shape= CONV5_1_SHAPE, name = 'I_level_conv')(feature_conv5)\n",
    "    #residual block\n",
    "    name = [\"I_resblock_1\",'I_resblock_2','I_resblock_3']\n",
    "    third_conv = resblock(one_one_conv, 512, CONV5_1_SHAPE, name)\n",
    "    #upsampling\n",
    "    upsampling = tf.keras.layers.UpSampling2D(size=2, name = 'I_level_upsampling')(third_conv)\n",
    "    #concatenation\n",
    "\n",
    "   # x = np.expand_dims(res[3], axis=0)\n",
    "\n",
    "    concat = tf.keras.layers.Concatenate(axis=3,name = 'I_level_concat')([upsampling, feature_conv4])\n",
    "    #######################\n",
    "\n",
    "    # 1x1 convolution\n",
    "    one_one_conv = tf.keras.layers.Conv2D(filters=512,kernel_size=1,padding = 'same',activation='relu',input_shape=concat.shape, name = 'II_level_conv')(concat)\n",
    "    #residual_block\n",
    "    name = [\"II_resblock_1\",'II_resblock_2','II_resblock_3']\n",
    "    third_conv = resblock(one_one_conv, 512, CONV4_1_SHAPE, name)\n",
    "    #upsampling \n",
    "    upsampling = tf.keras.layers.UpSampling2D(size=2,  name = 'II_level_upsampling')(third_conv)\n",
    "    #concatenation\n",
    "    #vgg3 = model.get_layer('block3_conv3').output\n",
    "    #x = np.expand_dims(res[2], axis=0)\n",
    "    \n",
    "    concat = tf.keras.layers.Concatenate(axis=3, name = 'II_level_concat')([upsampling, feature_conv3])\n",
    "\n",
    "    #####################################\n",
    "\n",
    "    # 1x1 convolution\n",
    "    one_one_conv = tf.keras.layers.Conv2D(filters=256,kernel_size=1,padding = 'same',activation='relu',input_shape=concat.shape, name = 'III_level_conv')(concat)\n",
    "    #residual_block\n",
    "    name = [\"III_resblock_1\",'III_resblock_2','III_resblock_3']\n",
    "    third_conv = resblock(one_one_conv, 256, CONV3_1_SHAPE, name)\n",
    "    #upsampling \n",
    "    upsampling = tf.keras.layers.UpSampling2D(size=2,  name = 'III_level_upsampling')(third_conv)\n",
    "    #concatenation\n",
    "    #vgg2 = model.get_layer('block2_conv2').output\n",
    "    #x = np.expand_dims(res[1], axis=0)  # alternativax =  res[1][np.newaxis is None,:,:,:]\n",
    "    \n",
    "    concat = tf.keras.layers.Concatenate(axis=3, name = 'III_level_concat')([upsampling, feature_conv2])\n",
    "\n",
    "    #############################################################################################\n",
    "\n",
    "\n",
    "    # 1x1 convolution\n",
    "    one_one_conv = tf.keras.layers.Conv2D(filters=128,kernel_size=1,padding = 'same',activation='relu',input_shape=concat.shape, name = 'IV_level_conv')(concat)\n",
    "    #residual_block \n",
    "    name = [\"IV_resblock_1\",'IV_resblock_2','IV_resblock_3']\n",
    "    third_conv = resblock(one_one_conv, 128, CONV2_1_SHAPE, name)\n",
    "    #upsampling \n",
    "    upsampling = tf.keras.layers.UpSampling2D(size=2,  name = 'IV_level_upsampling')(third_conv)\n",
    "    #concatenation\n",
    "    #vgg1 = model.get_layer('block1_conv2').output\n",
    "    #x = np.expand_dims(res[0], axis=0)\n",
    "    concat = tf.keras.layers.Concatenate(axis=3, name = 'IV_level_concat')([upsampling, feature_conv1])\n",
    "\n",
    "    ###############################################################\n",
    "\n",
    "    # 1x1 convolution\n",
    "    one_one_conv = tf.keras.layers.Conv2D(filters=128,kernel_size=1,padding = 'same',activation='relu',input_shape=concat.shape, name = 'V_level_conv')(concat)\n",
    "    #last residual_block \n",
    "    name = [\"V_resblock_1\",'V_resblock_2','V_resblock_3']\n",
    "    third_conv = resblock(one_one_conv, 128, CONV1_1_SHAPE, name )\n",
    "    #encoding texture\n",
    "    encode_texture = tf.keras.layers.Conv2D(filters=64,kernel_size=1,padding = 'same',input_shape= CONV1_1_SHAPE, name = 'encode')(third_conv)\n",
    "\n",
    "    mod = tf.keras.models.Model(inputs=[feature_conv5,feature_conv4,feature_conv3,feature_conv2,feature_conv1],\n",
    "                                outputs= encode_texture)\n",
    "    return encode_texture,mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder():\n",
    "\n",
    "    cor = tf.keras.layers.Input(shape=(256,256,1), name = \"corr-tensor\")\n",
    "    feat_im = tf.keras.layers.Input(shape=(256,256,64), name = \"encoded-main-image\")\n",
    "\n",
    "    \n",
    "       \n",
    "    d_cor = tf.image.resize(cor,[16,16], name = \"resize corr-tensor\")\n",
    "    d_im = tf.image.resize(feat_im,[16,16], name = \"resize encoded-main-image\")\n",
    "    \n",
    "    feature_conv5 = tf.keras.layers.Input(shape=(16,16,512), name = 'vgg_conv5.1_feature')\n",
    "    feature_conv4 = tf.keras.layers.Input(shape=(32, 32, 512),name = 'vgg_conv4.1_feature')\n",
    "    feature_conv3 = tf.keras.layers.Input(shape=(64, 64, 256),name = 'vgg_conv3.1_feature')\n",
    "    feature_conv2 = tf.keras.layers.Input(shape= (128, 128, 128),name = 'vgg_conv2.1_feature')\n",
    "    feature_conv1 = tf.keras.layers.Input(shape= (256, 256, 64),name = 'vgg_conv1.1_feature')\n",
    "    \n",
    "\n",
    "\n",
    "    v = tf.keras.layers.Conv2D(filters =64, kernel_size=1, padding='SAME', input_shape = feature_conv5.shape,name = \"deconv5_vgg_feat\")(feature_conv5)\n",
    "\n",
    "    concatenate = tf.keras.layers.Concatenate(axis=3, name = \"decod_first_concat\")([d_cor,d_im, v])\n",
    "\n",
    "    #secondo strato \n",
    "    v = tf.keras.layers.Conv2D(filters =64, kernel_size=1, padding='SAME', name = 'II_level_conv_1')(concatenate)\n",
    "    v = resblock(v, 64, v.shape, [\"II_level_resblock_1\",\"II_level_resblock_2\",\"II_level_resblock_3\"])\n",
    "    v = tf.keras.layers.UpSampling2D(size=2, name = 'II_level_upsampling')(v)\n",
    "\n",
    "    d_cor = tf.image.resize(cor,[32,32],name = \"II_level_cor_resize\")\n",
    "    d_v = tf.keras.layers.Conv2D(filters =64,kernel_size=1,padding = 'same',activation='relu',input_shape=feature_conv4.shape, name = \"deconv4_vgg_feat\")(feature_conv4)\n",
    "\n",
    "    concat = tf.keras.layers.Concatenate(axis=3, name = \"II_level_concat_results\")([d_v, d_cor,v])\n",
    "\n",
    "\n",
    "\n",
    "    # terzo strato \n",
    "\n",
    "    v = tf.keras.layers.Conv2D(filters =64, kernel_size=1, padding='SAME',name =  'III_level_conv_1')(concat)\n",
    "    v = resblock(v, 64, v.shape, [\"III_level_resblock_1\",\"III_level_resblock_2\",\"III_level_resblock_3\"])\n",
    "    v = tf.keras.layers.UpSampling2D(size=2)(v)\n",
    "\n",
    "    d_cor = tf.image.resize(cor,[64,64],name = \"III_level_cor_resize\")\n",
    "    d_v = tf.keras.layers.Conv2D(filters =64,kernel_size=1,padding = 'same',activation='relu',input_shape=feature_conv3.shape,name = \"deconv3_vgg_feat\")(feature_conv3)\n",
    "\n",
    "    concat = tf.keras.layers.Concatenate(axis=3,name = \"III_level_concat_results\")([d_v, d_cor,v])\n",
    "\n",
    "\n",
    "    #quarto strato \n",
    "\n",
    "    v = tf.keras.layers.Conv2D(filters =64, kernel_size=1, padding='SAME', name =  'IV_level_conv_1')(concat)\n",
    "    v = resblock(v, 64, v.shape, [\"IV_level_resblock_1\",\"IV_level_resblock_2\",\"IV_level_resblock_3\"])\n",
    "    v = tf.keras.layers.UpSampling2D(size=2)(v)\n",
    "\n",
    "    d_cor = tf.image.resize(cor,[128,128],name = \"IV_level_cor_resize\")\n",
    "    d_v = tf.keras.layers.Conv2D(filters =64,kernel_size=1,padding = 'same',activation='relu',input_shape=feature_conv2.shape,name = \"deconv2_vgg_feat\")(feature_conv2)\n",
    "\n",
    "    concat = tf.keras.layers.Concatenate(axis=3,name = \"IV_level_concat_results\")([d_v, d_cor,v])\n",
    "\n",
    "\n",
    "    #quinto strato \n",
    "\n",
    "    v = tf.keras.layers.Conv2D(filters =64, kernel_size=1, padding='SAME', name =  'V_level_conv_1')(concat)\n",
    "    v = resblock(v, 64, v.shape, [\"V_level_resblock_1\",\"V_level_resblock_2\",\"V_level_resblock_3\"])\n",
    "    v = tf.keras.layers.UpSampling2D(size=2)(v)\n",
    "\n",
    "    #d_cor = tf.image.resize(cor,[256,256])--> not neeeded as soon is it at right dimension \n",
    "    \n",
    "    d_v = tf.keras.layers.Conv2D(filters =64,kernel_size=1,padding = 'same',activation='relu',input_shape=feature_conv1.shape,name = \"deconv1_vgg_feat\")(feature_conv1)\n",
    "\n",
    "    concat = tf.keras.layers.Concatenate(axis=3,name = \"V_level_concat_results\")([d_v,cor,v])\n",
    "\n",
    "    \n",
    "    \n",
    "    v = tf.keras.layers.Conv2D(filters =64, kernel_size=1, padding='SAME',name =  'last_conv_1')(concat)\n",
    "    v = resblock(v, 64, v.shape, [\"last_resblock_1\",\"last_resblock_2\",\"last_resblock_3\"])\n",
    "\n",
    "    \n",
    "    decode_mask = tf.keras.layers.Conv2D(filters =1, kernel_size=1, padding='SAME', activation=tf.sigmoid, name = \"final_decode_layer\")(v)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    mod = tf.keras.models.Model(inputs=[cor,feat_im, feature_conv1,feature_conv2,feature_conv3,\n",
    "                                       feature_conv4,feature_conv5], outputs = decode_mask)\n",
    "    return decode_mask, mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_vgg_features = extract_features(\"../elephant.jpg\",reference = \"im\") \n",
    "#encoded_im,m = encoder(dim_im)\n",
    "\n",
    "#texture_vgg_feature = extract_features(\"../elephant.jpg\",reference = \"ref\")\n",
    "#encoded_texture,m2 = encoder(dim_ref)\n",
    "\n",
    "# so we have the correlation \n",
    "#cor = correlation(encoded_im,encoded_texture)\n",
    "# per ora diminuisco i filtri \n",
    "#cor = tf.keras.layers.Conv2D(filters=1,kernel_size=1,padding = 'same',activation='relu',input_shape=cor.shape, name = 'second_1x1')(cor)\n",
    "\n",
    "#decode_mask, mod = decoder()\n",
    "\n",
    "\n",
    "#keras.utils.plot_model(mod, \"my_first_model_with_shape_info.png\", show_shapes=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda10374d56d606404d89697440b2a570f1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
