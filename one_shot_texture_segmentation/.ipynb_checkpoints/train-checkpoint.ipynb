{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import import_ipynb\n",
    "import econding_and_decoding\n",
    "import Data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONV5_1_SHAPE = (16, 16, 512)\n",
    "CONV4_1_SHAPE = (32, 32, 512)\n",
    "CONV3_1_SHAPE = (64,64,256)\n",
    "CONV2_1_SHAPE = (128,128,128)\n",
    "CONV1_1_SHAPE = (256,256,64)\n",
    "\n",
    "dim_im = [CONV5_1_SHAPE,CONV4_1_SHAPE,CONV3_1_SHAPE,CONV2_1_SHAPE,CONV1_1_SHAPE]\n",
    "\n",
    "############################################\n",
    "\n",
    "\n",
    "CONV5_1_SHAPE_REF = (4, 4, 512)\n",
    "CONV4_1_SHAPE_REF = (8, 8, 512)\n",
    "CONV3_1_SHAPE_REF = (16,16,256)\n",
    "CONV2_1_SHAPE_REF = (32,32,128)\n",
    "CONV1_1_SHAPE_REF = (64,64,64)\n",
    "\n",
    "\n",
    "dim_ref = [CONV5_1_SHAPE_REF,CONV4_1_SHAPE_REF,CONV3_1_SHAPE_REF,CONV2_1_SHAPE_REF,CONV1_1_SHAPE_REF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_pixelwise_crossentropy_loss(y_pred, y_gt):\n",
    "    # compute  crossentropy loss \n",
    "    l = tf.math.reduce_sum(tf.math.multiply(y_gt, tf.math.log(y_pred+10e-100)),axis = 1)\n",
    "    l = tf.math.reduce_sum(l, axis=1)\n",
    "    l = tf.math.reduce_sum(l, axis=1)\n",
    "    n = tf.math.reduce_sum(y_gt,axis = 1)\n",
    "    n = tf.math.reduce_sum(n,axis = 1)\n",
    "    n = tf.math.reduce_sum(n,axis = 1)\n",
    "    l = -1 * (l / n)\n",
    "    return l \n",
    "    \n",
    "\n",
    "    \n",
    "def total_loss(y_pred, y_gt):\n",
    "    return tf.math.reduce_mean(weighted_pixelwise_crossentropy_loss(y_pred, y_gt) + weighted_pixelwise_crossentropy_loss((1 - y_pred), (1 - y_gt))).numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the data \n",
    "batch_size = 8\n",
    "dl_train = Data_loader.Data_loader('train_texture.npy', batch_size)\n",
    "dl_val = Data_loader.Data_loader('val_texture.npy', batch_size)\n",
    "\n",
    "#initialize learning rate\n",
    "init_lr = 10e-5\n",
    "lrng_rt = init_lr\n",
    "\n",
    "# initialize optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate = lrng_rt, name='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batch1, batch2, batch3, batch4, batch5, mask, ref_ind1, ref_ind2, ref_ind3, ref_ind4, ref_ind5 = dl_train.get_batch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrainim  = (batch5, batch4, batch3, batch2, batch1)\n",
    "ytrain = mask\n",
    "\n",
    "xtrainref = (ref_ind5, ref_ind4, ref_ind3, ref_ind2, ref_ind1)\n",
    "\n",
    "\n",
    "_,encoder_image = econding_and_decoding.encoder(dim_im)\n",
    "encoded_images = encoder_image(xtrainim, training=True)\n",
    "print(\"finito con l'immagine\")\n",
    "\n",
    "_,encoder_ref = econding_and_decoding.encoder(dim_ref)\n",
    "\n",
    "encoded_ref_text = encoder_ref(xtrainref, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "c = ecoding_and_decoding.correlation(encoded_images,encoded_ref_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,decoder = econding_and_decoding.decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_mask = decoder((c,encoded_images,batch1, batch2, batch3, batch4, batch5),training = True)\n",
    "exp_mask = tf.dtypes.cast(exp_mask, tf.double)\n",
    "\n",
    "mask = tf.convert_to_tensor(mask, dtype=tf.double)\n",
    "\n",
    "loss = total_loss(exp_mask,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = encoder_image.trainable_weights + encoder_ref.trainable_weights + decoder.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finito con l'immagine\n",
      "finito encoding\n",
      "fine correlation\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a65a3296d57e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weights' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "batch1, batch2, batch3, batch4, batch5, mask, ref_ind1, ref_ind2, ref_ind3, ref_ind4, ref_ind5 = dl_train.get_batch_data()\n",
    "with tf.GradientTape() as tape:\n",
    "    # encoding \n",
    "    xtrainim  = (batch5, batch4, batch3, batch2, batch1)\n",
    "    ytrain = mask\n",
    "\n",
    "    xtrainref = (ref_ind5, ref_ind4, ref_ind3, ref_ind2, ref_ind1)\n",
    "    \n",
    "    _,encoder_image = econding_and_decoding.encoder(dim_im)\n",
    "    encoded_images = encoder_image(xtrainim, training=True)\n",
    "    print(\"finito con l'immagine\")\n",
    "\n",
    "    _,encoder_ref = econding_and_decoding.encoder(dim_ref)\n",
    "\n",
    "    encoded_ref_text = encoder_ref(xtrainref, training=True)\n",
    "    \n",
    "    print(\"finito encoding\")\n",
    "    \n",
    "    #correlation\n",
    "    c = econding_and_decoding.correlation(encoded_images,encoded_ref_text)\n",
    "    \n",
    "    print(\"fine correlation\")\n",
    "    \n",
    "    \n",
    "    _,decoder = econding_and_decoding.decoder()\n",
    "    \n",
    "    exp_mask = decoder((c,encoded_images,batch1, batch2, batch3, batch4, batch5),training = True)\n",
    "    exp_mask = tf.dtypes.cast(exp_mask, tf.double)\n",
    "\n",
    "    mask = tf.convert_to_tensor(mask, dtype=tf.double)\n",
    "\n",
    "    loss = total_loss(exp_mask,mask)\n",
    "\n",
    "    \n",
    "weights = encoder_image.trainable_weights + encoder_ref.trainable_weights + decoder.trainable_weights\n",
    "grads = tape.gradient(loss, weights)\n",
    "\n",
    "\n",
    "opt.apply_gradients(zip(grads, weights))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda10374d56d606404d89697440b2a570f1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
